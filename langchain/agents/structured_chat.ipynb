{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [TavilySearchResults(max_results=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "# Construct the JSON agent\n",
    "agent = create_structured_chat_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"tavily_search_results_json\",\n",
      "  \"action_input\": {\"query\": \"LangChain\"}\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.langchain.com/langchain', 'content': 'Augment the power\\nof\\xa0LLMs with your data\\nLangChain helps connect LLMs to your company’s private sources\\nof data and APIs to create context-aware, reasoning applications.\\n Our Methods\\nReady to start shipping\\nreliable GenAI apps faster?\\nLangChain and LangSmith are critical parts of the reference\\narchitecture to get you from prototype to production. The largest community building the future of LLM apps\\nLangChain’s flexible abstractions and AI-first toolkit make it\\xa0the\\xa0#1\\xa0choice for developers when building with GenAI.\\n Why choose LangChain?\\nLangChain is easy to get started with and\\xa0gives\\xa0you choice, flexibility, and power as\\xa0you scale.\\n Get customizability and control with a durable runtime baked in\\nLangChain Expression Language (LCEL) lets you build your app in a truly composable way, allowing you to customize it as you see fit.'}]\u001b[0m\u001b[32;1m\u001b[1;3mLangChain is a platform that helps connect LLMs (Large Language Models) to a company's private sources of data and APIs to create context-aware, reasoning applications. It offers flexible abstractions and an AI-first toolkit for developers building with GenAI. LangChain also provides customizability and control with a durable runtime baked in, and its LangChain Expression Language (LCEL) allows for building apps in a composable way. You can learn more about LangChain at [LangChain](https://www.langchain.com/langchain).\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"LangChain is a platform that helps connect LLMs to a company's private sources of data and APIs to create context-aware, reasoning applications. It offers flexible abstractions and an AI-first toolkit for developers building with GenAI. LangChain also provides customizability and control with a durable runtime baked in, and its LangChain Expression Language (LCEL) allows for building apps in a composable way. You can learn more about LangChain at https://www.langchain.com/langchain.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is LangChain?',\n",
       " 'output': \"LangChain is a platform that helps connect LLMs to a company's private sources of data and APIs to create context-aware, reasoning applications. It offers flexible abstractions and an AI-first toolkit for developers building with GenAI. LangChain also provides customizability and control with a durable runtime baked in, and its LangChain Expression Language (LCEL) allows for building apps in a composable way. You can learn more about LangChain at https://www.langchain.com/langchain.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is LangChain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using with chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: I'm sorry, I cannot assist with that without using tools.\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: I'm sorry, I cannot assist with that without using tools.\n",
      "\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: I'm sorry, I cannot assist with that without using tools.\n",
      "\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"tavily_search_results_json\",\n",
      "  \"action_input\": {\"query\": \"What is my name?\"}\n",
      "}\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.thebump.com/b/meaning-of-my-name', 'content': 'Discover the cultural, historical, and linguistic roots of your name and how they shape your identity and destiny. Enter your name and get insights into its significance, hidden stories, and potential influences.'}]\u001b[0m\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Your name is Bob.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name? Do not use tools unless you have to\",\n",
       " 'chat_history': [HumanMessage(content='hi! my name is bob'),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'output': 'Your name is Bob.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"what's my name? Do not use tools unless you have to\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! my name is bob\"),\n",
    "            AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
