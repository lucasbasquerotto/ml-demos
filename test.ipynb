{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the MUJOCO_GL environment variable to a different backend\n",
    "os.environ['MUJOCO_GL'] = 'glfw'  # or 'osmesa', 'gl'\n",
    "\n",
    "# Import and use MuJoCo environments\n",
    "import gymnasium as gym\n",
    "\n",
    "# Example usage\n",
    "env = gym.make('Humanoid-v5', render_mode='human')\n",
    "env.reset()\n",
    "env.render()\n",
    "\n",
    "# do some demo actions\n",
    "for _ in range(1000):\n",
    "    env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "\n",
    "gym.register_envs(ale_py)\n",
    "\n",
    "env = gym.make('ALE/Breakout-v5')\n",
    "obs, info = env.reset()\n",
    "obs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "env.close()\n",
    "\n",
    "# render the environment\n",
    "import time\n",
    "env = gym.make('ALE/Breakout-v5', render_mode='human')\n",
    "env.reset()\n",
    "\n",
    "for _ in range(100):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample())\n",
    "    env.step(env.action_space.sample())\n",
    "    time.sleep(0.1)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "q_t^{\\lambda} = (1 - \\lambda) \\sum_{n = 1}^{\\infty} \\lambda^{n - 1} q_t^{(n)}\n",
    "\\end{align*}\n",
    "\n",
    "Considering weight $w(n) = (1 - \\lambda)\\lambda^{n-1}$:\n",
    "\n",
    "\\begin{align*}\n",
    "\\sum_{n = 1}^N w(n) &= \\sum_{n = 1}^N (1 - \\lambda)\\lambda^{n-1} \\\\\n",
    "\\sum_{n = 1}^N w(n) - \\lambda \\sum_{n = 1}^N w(n) &= (1 - \\lambda) \\sum_{n = 1}^N \\lambda^{n-1} - (1 - \\lambda) \\lambda \\sum_{n = 1}^N \\lambda^{n-1} \\\\\n",
    "(1 - \\lambda) \\sum_{n = 1}^N w(n) &= (1 - \\lambda) \\sum_{n = 1}^N \\lambda^{n-1} - (1 - \\lambda) \\sum_{n = 2}^{N + 1} \\lambda^{n-1} \\\\\n",
    "(1 - \\lambda) \\sum_{n = 1}^N w(n) &= (1 - \\lambda) \\left[ \\left( \\lambda^0 + \\sum_{n = 2}^N \\lambda^{n-1} \\right) - \\left( \\sum_{n = 2}^N \\lambda^{n-1} + \\lambda^N \\right) \\right] \\\\\n",
    "(1 - \\lambda) \\sum_{n = 1}^N w(n) &= (1 - \\lambda) \\left[ 1 - \\lambda^N \\right] \\\\\n",
    "\\sum_{n = 1}^N w(n) &= 1 - \\lambda^N\n",
    "\\end{align*}\n",
    "\n",
    "Also, for $0 < \\lambda < 1$:\n",
    "\n",
    "\\begin{align*}\n",
    "\\operatorname*{lim}_{k \\to \\infty} \\sum_{n = 1}^k w(n) = \\operatorname*{lim}_{k \\to \\infty} [1 - \\lambda^k] = 1\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import TransformObservation\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "print(env.reset(seed=42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TransformObservation(env, lambda obs: obs + 0.1 * np.random.randn(*obs.shape))\n",
    "env.reset(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.1 * np.random.randn(*[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ema(data, gamma):\n",
    "    ema = 0\n",
    "    emas = []\n",
    "    for x in data:\n",
    "        ema = gamma * ema + (1 - gamma) * x\n",
    "        emas.append(ema)\n",
    "    return ema, emas\n",
    "\n",
    "rewards = [1, 3, -20, 10, 100, -50, 12, 13]  # list of rewards\n",
    "gamma = 0.9  # decay factor\n",
    "\n",
    "# Calculate EMA of rewards\n",
    "_, ema_rewards = calculate_ema(rewards, gamma)\n",
    "print('ema_rewards', ema_rewards)\n",
    "\n",
    "# Calculate EMA of squared rewards\n",
    "squared_rewards = [r**2 for r in rewards]\n",
    "_, ema_squared_rewards = calculate_ema(squared_rewards, gamma)\n",
    "print('ema_squared_rewards', ema_squared_rewards)\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(rewards, label=\"rewards\")\n",
    "plt.plot(ema_rewards, label=\"EMA rewards\")\n",
    "plt.plot(squared_rewards, label=\"squared rewards\")\n",
    "plt.plot(ema_squared_rewards, label=\"EMA squared rewards\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
