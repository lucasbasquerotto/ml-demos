{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('kaggle/input/digit-recognizer/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data)\n",
    "\n",
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "X_dev = X_dev / 255.\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    W1 = np.random.rand(10, n-1) - 0.5 # 784 features\n",
    "    b1 = np.random.rand(10, 1) - 0.5 # 10 classes (labels)\n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2) # wrong A2 = softmax(A1)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1)) # size x classes\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def derive_ReLU(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def back_prop(Z1, A1, Z2, A2, W2, X, Y):\n",
    "    m = Y.size\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1/m * dZ2.dot(A1.T)\n",
    "    db2 = 1/m * np.sum(dZ2, axis=1)\n",
    "    dZ1 = W2.T.dot(dZ2) * derive_ReLU(Z1)\n",
    "    dW1 = 1/m * dZ1.dot(X.T)\n",
    "    db1 = 1/m * np.sum(dZ1, axis=1)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * np.reshape(db1, (10, 1))\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * np.reshape(db2, (10, 1))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, iterations, alpha):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            print(\"Accuracy: \", get_accuracy(get_predictions(A2), Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[4 2 5 ... 4 2 2] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.10066101694915254\n",
      "Iteration:  10\n",
      "[7 4 6 ... 3 4 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.216\n",
      "Iteration:  20\n",
      "[3 4 6 ... 6 4 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.30083050847457626\n",
      "Iteration:  30\n",
      "[3 4 6 ... 6 4 8] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.3778135593220339\n",
      "Iteration:  40\n",
      "[3 4 6 ... 6 4 8] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.4569491525423729\n",
      "Iteration:  50\n",
      "[3 9 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.5126101694915254\n",
      "Iteration:  60\n",
      "[3 9 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.5566949152542373\n",
      "Iteration:  70\n",
      "[3 9 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.5947457627118644\n",
      "Iteration:  80\n",
      "[3 9 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.6241694915254238\n",
      "Iteration:  90\n",
      "[3 9 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.6497457627118645\n",
      "Iteration:  100\n",
      "[3 9 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.6697966101694915\n",
      "Iteration:  110\n",
      "[8 9 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.6864237288135593\n",
      "Iteration:  120\n",
      "[8 9 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7006271186440678\n",
      "Iteration:  130\n",
      "[8 9 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7121016949152542\n",
      "Iteration:  140\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7229152542372881\n",
      "Iteration:  150\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7330677966101695\n",
      "Iteration:  160\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7417627118644068\n",
      "Iteration:  170\n",
      "[8 4 6 ... 6 9 5] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7495593220338983\n",
      "Iteration:  180\n",
      "[8 4 6 ... 6 9 5] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7567796610169492\n",
      "Iteration:  190\n",
      "[8 4 6 ... 6 9 5] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7638474576271187\n",
      "Iteration:  200\n",
      "[8 4 6 ... 6 9 5] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7699661016949153\n",
      "Iteration:  210\n",
      "[8 4 6 ... 6 9 5] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7755254237288136\n",
      "Iteration:  220\n",
      "[8 4 6 ... 6 9 5] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7809322033898305\n",
      "Iteration:  230\n",
      "[8 4 6 ... 6 9 5] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7852881355932203\n",
      "Iteration:  240\n",
      "[8 4 6 ... 6 9 5] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7894915254237288\n",
      "Iteration:  250\n",
      "[8 4 6 ... 6 9 5] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7936779661016949\n",
      "Iteration:  260\n",
      "[8 4 6 ... 6 9 5] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.7971694915254237\n",
      "Iteration:  270\n",
      "[8 4 6 ... 6 9 5] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8007796610169492\n",
      "Iteration:  280\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8037966101694916\n",
      "Iteration:  290\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8075084745762712\n",
      "Iteration:  300\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8107118644067797\n",
      "Iteration:  310\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8135593220338984\n",
      "Iteration:  320\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8160508474576271\n",
      "Iteration:  330\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8185932203389831\n",
      "Iteration:  340\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8213389830508474\n",
      "Iteration:  350\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8235762711864407\n",
      "Iteration:  360\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8251016949152542\n",
      "Iteration:  370\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8269491525423729\n",
      "Iteration:  380\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8293050847457627\n",
      "Iteration:  390\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.831135593220339\n",
      "Iteration:  400\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.833\n",
      "Iteration:  410\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8345932203389831\n",
      "Iteration:  420\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8359830508474576\n",
      "Iteration:  430\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8375932203389831\n",
      "Iteration:  440\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8388305084745763\n",
      "Iteration:  450\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8402881355932204\n",
      "Iteration:  460\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8416271186440678\n",
      "Iteration:  470\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8429322033898305\n",
      "Iteration:  480\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8444915254237289\n",
      "Iteration:  490\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8456949152542372\n",
      "Iteration:  500\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8470169491525423\n",
      "Iteration:  510\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8480508474576272\n",
      "Iteration:  520\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8490677966101695\n",
      "Iteration:  530\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8502881355932204\n",
      "Iteration:  540\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8513389830508474\n",
      "Iteration:  550\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8521525423728814\n",
      "Iteration:  560\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8532033898305085\n",
      "Iteration:  570\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8540508474576272\n",
      "Iteration:  580\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8548813559322034\n",
      "Iteration:  590\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8557966101694915\n",
      "Iteration:  600\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8565593220338983\n",
      "Iteration:  610\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8571694915254238\n",
      "Iteration:  620\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8578983050847457\n",
      "Iteration:  630\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8589661016949153\n",
      "Iteration:  640\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8596101694915255\n",
      "Iteration:  650\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8606779661016949\n",
      "Iteration:  660\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.861457627118644\n",
      "Iteration:  670\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8622203389830508\n",
      "Iteration:  680\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8628135593220339\n",
      "Iteration:  690\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8635593220338983\n",
      "Iteration:  700\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8641694915254238\n",
      "Iteration:  710\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8648813559322034\n",
      "Iteration:  720\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8654915254237288\n",
      "Iteration:  730\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8661016949152542\n",
      "Iteration:  740\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8666949152542373\n",
      "Iteration:  750\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8671864406779661\n",
      "Iteration:  760\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8677288135593221\n",
      "Iteration:  770\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8682881355932204\n",
      "Iteration:  780\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8690847457627119\n",
      "Iteration:  790\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8697796610169491\n",
      "Iteration:  800\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8702542372881356\n",
      "Iteration:  810\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8707627118644068\n",
      "Iteration:  820\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8714915254237288\n",
      "Iteration:  830\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8720169491525424\n",
      "Iteration:  840\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8724745762711864\n",
      "Iteration:  850\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8729830508474576\n",
      "Iteration:  860\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8732881355932204\n",
      "Iteration:  870\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8737457627118644\n",
      "Iteration:  880\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8741186440677966\n",
      "Iteration:  890\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8743728813559322\n",
      "Iteration:  900\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8749661016949153\n",
      "Iteration:  910\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8753220338983051\n",
      "Iteration:  920\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8757288135593221\n",
      "Iteration:  930\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8762372881355932\n",
      "Iteration:  940\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8766271186440678\n",
      "Iteration:  950\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8771525423728813\n",
      "Iteration:  960\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8775593220338983\n",
      "Iteration:  970\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8779152542372881\n",
      "Iteration:  980\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.878135593220339\n",
      "Iteration:  990\n",
      "[8 4 6 ... 6 9 3] [8 4 6 ... 6 9 5]\n",
      "Accuracy:  0.8786101694915254\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 1000, 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_predictions(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [5]\n",
      "Label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions(701, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 6 8 9 7 3 7 8 6 4 5 2 3 1 4 6 9 7 3 1 3 1 6 5 8 1 7 1 3 1 6 8 0 3 6 2 1\n",
      " 4 0 9 1 7 6 3 4 9 7 2 7 5 8 6 6 5 4 6 6 5 5 1 0 0 3 4 1 4 4 8 1 3 0 1 9 2\n",
      " 0 7 3 5 5 4 2 7 5 3 2 0 0 8 6 0 9 2 1 7 0 9 0 7 1 8 8 0 1 0 8 2 3 8 1 9 1\n",
      " 0 5 4 3 7 9 9 0 3 9 0 0 5 6 2 2 9 5 9 6 3 5 2 1 5 9 1 2 4 7 8 3 4 6 7 8 0\n",
      " 8 8 1 7 6 8 9 6 8 8 8 4 2 5 9 6 1 1 8 7 5 0 0 2 3 0 4 8 6 0 8 5 0 1 1 5 9\n",
      " 3 6 7 9 9 5 5 2 5 1 4 5 6 9 8 0 8 5 7 2 1 6 4 5 4 7 8 0 6 3 8 1 7 7 7 5 1\n",
      " 3 9 0 0 7 0 4 6 7 5 2 0 1 1 1 4 3 1 0 5 9 4 5 8 7 2 9 5 9 3 7 8 5 0 8 0 4\n",
      " 1 8 7 4 8 6 6 3 1 3 7 8 5 4 9 3 4 4 2 4 7 8 3 3 9 1 9 9 7 3 8 0 3 9 2 1 2\n",
      " 6 7 0 7 4 9 7 8 9 8 9 7 8 8 1 3 8 9 3 9 0 6 3 8 6 7 4 6 6 5 1 1 2 6 5 6 1\n",
      " 5 7 0 5 8 9 5 9 0 2 6 9 6 3 0 6 5 2 1 6 5 0 4 8 7 1 1 8 0 1 7 6 0 3 0 7 5\n",
      " 0 6 3 4 6 2 5 4 9 8 4 2 9 0 1 1 4 8 5 0 2 4 3 6 8 0 3 1 4 5 1 3 8 4 9 7 1\n",
      " 8 0 6 5 6 8 8 7 3 4 0 1 9 1 6 9 1 9 2 5 2 6 6 2 3 7 5 9 2 5 7 5 9 6 6 0 5\n",
      " 3 9 1 2 9 1 4 9 0 5 0 3 0 2 3 6 0 4 0 5 4 4 6 3 5 8 8 2 8 6 6 6 7 8 9 5 3\n",
      " 9 5 8 2 3 7 6 7 1 0 1 3 3 6 0 4 6 5 0 6 9 1 1 9 9 8 1 6 7 1 2 9 5 6 6 7 0\n",
      " 1 0 7 5 3 7 5 9 8 9 6 8 7 4 3 7 5 3 5 0 3 6 6 3 8 8 1 5 1 0 3 5 0 4 1 9 8\n",
      " 3 1 6 9 1 0 4 9 4 5 0 1 8 9 6 1 6 9 8 1 4 7 4 2 9 8 6 7 7 6 7 3 6 0 3 3 4\n",
      " 9 6 8 9 3 5 6 7 2 5 4 4 3 4 8 8 9 1 0 1 0 7 1 3 8 8 9 6 7 5 5 5 1 8 0 8 0\n",
      " 3 8 4 1 0 6 1 3 3 3 7 1 9 9 0 9 5 7 3 7 8 9 8 1 8 2 9 6 2 0 7 9 6 9 7 5 8\n",
      " 9 8 1 0 8 8 3 7 4 0 6 1 2 8 1 1 1 0 5 1 3 8 7 6 6 6 2 1 6 1 5 5 5 8 3 2 6\n",
      " 1 8 6 4 6 4 4 4 3 6 9 1 8 7 9 2 0 6 0 5 0 6 9 2 6 3 9 0 2 8 1 0 3 8 6 1 9\n",
      " 3 9 8 2 8 5 6 6 9 3 4 3 6 2 1 6 9 9 8 4 7 3 1 0 6 0 7 2 1 4 0 2 3 9 3 9 6\n",
      " 0 8 3 7 0 3 0 2 1 7 1 8 6 2 3 6 9 4 2 7 7 7 2 1 3 8 0 3 3 0 3 4 9 7 2 5 4\n",
      " 4 7 4 4 1 3 3 0 2 3 2 0 9 1 2 5 7 4 3 8 3 2 6 7 5 5 8 3 9 9 1 0 0 1 7 1 3\n",
      " 4 0 8 6 0 1 3 9 8 9 8 3 8 1 4 9 1 0 1 1 3 0 0 0 4 6 9 2 5 0 8 8 6 7 9 9 4\n",
      " 6 3 5 3 6 3 5 8 2 6 6 6 0 4 5 8 3 0 7 5 3 1 3 5 0 0 6 2 6 1 3 4 8 7 4 3 1\n",
      " 7 8 0 7 7 9 2 4 4 7 4 4 3 3 9 4 3 2 0 2 0 5 3 4 7 8 7 4 2 8 6 8 1 4 4 4 1\n",
      " 9 7 6 1 4 5 7 2 5 6 4 7 6 3 8 1 7 5 9 3 6 8 9 3 6 2 1 1 3 3 4 9 8 8 1 6 7\n",
      " 1] [0 6 8 9 7 3 7 9 6 4 5 2 3 1 4 5 9 7 3 1 3 1 6 5 9 1 7 1 3 1 6 8 0 3 6 2 1\n",
      " 4 0 9 1 7 6 5 4 8 7 2 7 5 8 3 6 8 4 6 6 3 5 1 0 0 3 4 1 4 9 8 1 8 0 1 9 2\n",
      " 0 7 3 3 5 4 2 0 5 3 2 0 2 8 6 0 9 2 1 7 0 9 0 7 1 8 8 0 1 0 8 0 3 8 1 9 1\n",
      " 0 5 4 3 7 9 9 0 9 9 0 0 1 6 2 2 9 5 9 6 3 5 2 1 5 9 1 2 4 7 8 3 4 6 7 8 0\n",
      " 8 8 1 7 6 2 9 6 8 8 8 4 2 5 3 6 1 1 4 7 5 0 0 1 3 0 4 8 6 0 8 5 0 1 1 5 9\n",
      " 2 6 7 9 4 5 5 2 5 1 4 8 6 9 8 0 8 5 7 2 1 6 4 5 4 7 8 0 6 3 8 1 7 7 2 5 2\n",
      " 3 9 0 0 7 0 4 2 7 5 0 0 8 1 1 4 3 1 0 5 9 4 5 5 7 9 9 5 9 3 7 8 5 0 8 0 4\n",
      " 1 8 7 4 8 6 6 3 1 3 7 8 5 4 9 3 9 4 2 4 7 8 3 3 9 1 9 9 7 3 8 0 3 9 2 1 2\n",
      " 6 9 0 7 4 9 7 8 9 8 9 7 8 6 1 3 8 9 3 9 0 6 2 8 6 7 4 6 6 5 1 1 2 6 5 6 1\n",
      " 5 7 0 5 8 4 5 9 0 2 6 9 6 3 0 6 5 2 1 6 5 0 4 1 7 1 1 8 0 5 7 5 0 3 0 7 5\n",
      " 0 6 2 4 6 2 8 4 4 8 4 2 9 0 1 1 4 8 5 0 2 9 3 6 8 0 3 1 2 5 1 3 0 4 9 7 5\n",
      " 8 0 6 5 5 8 8 7 3 4 0 1 9 1 6 9 1 9 2 5 2 6 6 2 5 7 5 9 2 5 7 5 4 8 6 0 5\n",
      " 3 9 1 2 9 1 4 9 0 5 0 3 0 2 3 8 0 4 0 5 4 4 6 3 5 8 8 2 8 6 6 2 7 3 9 5 3\n",
      " 9 5 8 2 3 7 6 7 1 0 1 2 7 6 0 4 6 5 0 6 9 1 1 9 9 8 1 6 7 1 2 9 5 5 6 7 0\n",
      " 1 0 7 5 3 7 5 9 8 9 6 8 7 4 3 7 5 3 5 0 3 6 6 5 6 8 1 5 1 0 3 0 0 4 1 9 8\n",
      " 3 4 6 4 1 3 4 9 4 5 0 1 8 9 6 1 6 9 8 1 4 7 4 3 9 8 6 7 7 6 3 3 6 0 3 3 4\n",
      " 9 6 8 9 3 5 6 7 2 5 4 4 3 9 8 8 9 1 0 1 0 7 1 8 8 8 9 6 7 5 3 8 1 8 0 3 0\n",
      " 3 8 4 1 0 6 1 3 3 3 7 1 9 4 0 9 3 7 3 7 8 5 8 1 5 2 9 6 2 0 7 7 3 9 7 5 8\n",
      " 4 8 1 0 8 8 3 7 4 0 6 1 2 8 1 1 1 0 5 7 3 3 7 6 8 6 2 1 6 1 5 5 5 8 3 2 6\n",
      " 1 8 6 4 6 4 4 9 3 6 9 1 8 7 4 5 0 6 0 5 0 6 9 2 6 3 9 0 2 8 1 0 3 3 6 1 9\n",
      " 3 9 8 2 8 5 6 6 9 3 4 3 6 2 1 6 9 9 2 4 7 3 1 0 6 0 7 2 1 4 0 2 3 9 3 9 6\n",
      " 0 8 3 7 0 3 7 2 6 7 1 8 6 2 3 6 9 4 8 7 7 7 2 1 3 8 0 3 3 0 3 4 9 7 2 5 4\n",
      " 4 7 4 4 1 3 3 0 2 3 2 0 9 1 2 9 7 4 8 8 3 2 6 7 3 3 8 3 9 7 1 0 0 1 7 1 5\n",
      " 4 0 8 6 0 1 3 8 8 9 8 8 8 1 2 9 1 0 1 1 3 0 0 0 4 6 9 2 3 0 8 8 6 7 7 9 4\n",
      " 6 3 5 3 6 3 3 0 2 6 6 6 0 4 5 8 3 0 7 5 3 1 3 5 8 0 6 2 5 1 3 4 6 7 0 3 1\n",
      " 5 1 0 7 7 2 2 2 4 7 4 4 3 3 4 4 3 2 0 4 0 5 8 4 9 8 7 4 2 8 6 8 1 4 4 4 1\n",
      " 9 7 6 1 4 5 7 2 5 5 4 9 6 3 8 1 7 5 4 5 6 8 9 3 6 2 1 1 3 3 4 9 8 8 3 6 7\n",
      " 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.884"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\n",
    "get_accuracy(dev_predictions, Y_dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
