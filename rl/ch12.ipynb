{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12 - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.1\n",
    "\n",
    "**Q**\n",
    "\n",
    "Just as the return can be written recursively in terms of the first reward and itself one-step later (3.9), so can the-return. Derive the analogous recursive relationship from (12.2) and (12.1).\n",
    "\n",
    "**A**\n",
    "\n",
    "The return written recursively in terms of the first reward and itself one-step later (3.9):\n",
    "\n",
    "\\begin{align*}\n",
    "G_t &\\doteq R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\gamma^3 R_{t+4} + ... \\\\\n",
    "&= R_{t+1} + \\gamma (R_{t+2} + \\gamma R_{t+3} + \\gamma^2 R_{t+4} + ...) \\\\\n",
    "&= R_{t+1} + \\gamma G_{t+1} \\tag{3.9}\n",
    "\\end{align*}\n",
    "\n",
    "Equation 12.2 is:\n",
    "\n",
    "$$\n",
    "G_t^{\\lambda} \\doteq (1 - \\lambda) \\sum_{n=1}^{\\infty} \\lambda^{n-1} G_{t:t+n} \\tag{12.2}\n",
    "$$\n",
    "\n",
    "Equation 12.1 is:\n",
    "\n",
    "$$\n",
    "G_{t:t+n} \\doteq R_{t+1} + \\gamma R_{t+2} + ... + \\gamma^{n-1} R_{t+n} + \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}_{t+n-1}), \\quad 0 \\leq t \\leq T - n \\tag{12.1}\n",
    "$$\n",
    "\n",
    "From 12.1 and considering the reasoning used in 3.9, we have:\n",
    "\n",
    "\\begin{align*}\n",
    "G_{t:t+n} &\\doteq R_{t+1} + \\gamma R_{t+2} + ... + \\gamma^{n-1} R_{t+n} + \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}_{t+n-1}) \\\\\n",
    "&= R_{t+1} + \\gamma (R_{t+2} + ... + \\gamma^{n-2} R_{t+n} + \\gamma^{n-1} \\widehat{v}(S_{t+n}, \\textbf{w}_{t+n-1})) \\\\\n",
    "&= R_{t+1} + \\gamma G_{t+1:t+n}, \\quad 0 \\leq t \\leq T - n \\tag{a1}\n",
    "\\end{align*}\n",
    "\n",
    "Then:\n",
    "\n",
    "\\begin{align*}\n",
    "G_t^{\\lambda} &\\doteq (1 - \\lambda) \\sum_{n=1}^{\\infty} \\lambda^{n-1} G_{t:t+n} \\\\\n",
    "&= (1 - \\lambda) \\left[ \\lambda^{1-1} G_{t:t+1} + \\sum_{n=2}^{\\infty} \\lambda^{n-1} G_{t:t+n} \\right] \\\\\n",
    "&= (1 - \\lambda) G_{t:t+1} + (1 - \\lambda) \\sum_{n=2}^{\\infty} \\lambda^{n-1} G_{t:t+n} \\\\\n",
    "&= (1 - \\lambda) G_{t:t+1} + (1 - \\lambda) \\sum_{n=1}^{\\infty} \\lambda^{(n+1)-1} G_{t:t+(n+1)} \\\\\n",
    "&= (1 - \\lambda) G_{t:t+1} + (1 - \\lambda) \\sum_{n=1}^{\\infty} \\lambda^n G_{t:t+(n+1)} \\\\\n",
    "&= (1 - \\lambda) G_{t:t+1} + (1 - \\lambda) \\lambda \\sum_{n=1}^{\\infty} \\lambda^{n-1} G_{t:t+(n+1)} \\\\\n",
    "&= (1 - \\lambda) G_{t:t+1} + (1 - \\lambda) \\lambda \\sum_{n=1}^{\\infty} \\lambda^{n-1} \\left(R_{t+1} + \\gamma G_{t+1:t+(n+1)} \\right) \\tag{from a1} \\\\\n",
    "&= (1 - \\lambda) G_{t:t+1} + (1 - \\lambda) \\lambda \\sum_{n=1}^{\\infty} \\lambda^{n-1} \\left(R_{t+1} + \\gamma G_{t+1:(t+1)+n} \\right) \\\\\n",
    "&= (1 - \\lambda) G_{t:t+1} + \\left[ (1 - \\lambda) \\lambda \\sum_{n=1}^{\\infty} \\lambda^{n-1} R_{t+1} \\right] + \\left[ (1 - \\lambda) \\lambda \\sum_{n=1}^{\\infty} \\lambda^{n-1} \\gamma G_{t+1:(t+1)+n} \\right] \\\\\n",
    "&= (1 - \\lambda) G_{t:t+1} + \\left[ (1 - \\lambda) \\lambda R_{t+1} \\sum_{n=1}^{\\infty} \\lambda^{n-1} \\right] + \\lambda \\gamma \\left[ (1 - \\lambda) \\sum_{n=1}^{\\infty} \\lambda^{n-1} G_{t+1:(t+1)+n} \\right] \\\\\n",
    "&= (1 - \\lambda) G_{t:t+1} + \\left[ (1 - \\lambda) \\lambda R_{t+1} \\operatorname*{lim}_{k \\to \\infty} \\left( \\frac{1 - \\lambda^k}{1 - \\lambda} \\right) \\right] + \\lambda \\gamma G_{t+1}^{\\lambda} \\tag{from 12.2} \\\\\n",
    "&= (1 - \\lambda) G_{t:t+1} + \\left[ (1 - \\lambda) \\lambda R_{t+1} \\frac{1}{1 - \\lambda} \\right] + \\lambda \\gamma G_{t+1}^{\\lambda} \\\\\n",
    "&= (1 - \\lambda) G_{t:t+1} + \\lambda R_{t+1} + \\lambda \\gamma G_{t+1}^{\\lambda} \\\\\n",
    "&= (1 - \\lambda) [ R_{t+1} + \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}_t) ] + \\lambda R_{t+1} + \\lambda \\gamma G_{t+1}^{\\lambda} \\\\\n",
    "&= R_{t+1} + \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}_t) - \\lambda R_{t+1} - \\lambda \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}_t) + \\lambda R_{t+1} + \\lambda \\gamma G_{t+1}^{\\lambda} \\\\\n",
    "&= R_{t+1} + (1 - \\lambda) \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}_t) + \\lambda \\gamma G_{t+1}^{\\lambda}\n",
    "\\end{align*}\n",
    "\n",
    "with $\\widehat{v}(S_{t+1}, \\textbf{w}_t)$ being the estimated value of the next state ($S_{t+1}$) at time $t$ (this can be calculated right after the action is executed at the time $t$, giving the reward $R_{t+1}$ and next state $S_{t+1}$; $\\textbf{w}_t$ is the weights vector at the time-step $t$).\n",
    "\n",
    "Note that:\n",
    "\n",
    "- $G_t^0 = R_{t+1} + (1 - 0) \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}_t) + 0 \\cdot \\gamma G_{t+1}^0 = R_{t+1} + \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}_t)$, which is the target of TD(0).\n",
    "\n",
    "- $G_t^1 = R_{t+1} + (1 - 1) \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}_t) + 1 \\cdot \\gamma G_{t+1}^1 = R_{t+1} + \\gamma G_{t+1}^1 = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 G_{t+2}^1 = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+2} + ... = G_t$, which is the target of Monte Carlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.2\n",
    "\n",
    "**Q**\n",
    "\n",
    "The parameter $\\lambda$ characterizes how fast the exponential weighting in Figure 12.2 falls off, and thus how far into the future the $\\lambda$-return algorithm looks in determining its update. But a rate factor such as $\\lambda$ is sometimes an awkward way of characterizing the speed of the decay. For some purposes it is better to specify a time constant, or half-life. What is the equation relating and the half-life, $\\tau_{\\lambda}$, the time by which the weighting sequence will have fallen to half of its initial value?\n",
    "\n",
    "**A**\n",
    "\n",
    "Equation 12.2 is:\n",
    "\n",
    "$$\n",
    "G_t^{\\lambda} \\doteq (1 - \\lambda) \\sum_{n=1}^{\\infty} \\lambda^{n-1} G_{t:t+n} \\tag{12.2}\n",
    "$$\n",
    "\n",
    "The $n\\text{th}$ weight is given by:\n",
    "\n",
    "$$\n",
    "W_n = (1 - \\lambda) \\lambda^{n-1}\n",
    "$$\n",
    "\n",
    "What we want is to find $n = \\tau_{\\lambda}$ such that $W_{\\tau_{\\lambda}} = \\frac{1}{2} W_1$:\n",
    "\n",
    "\\begin{align*}\n",
    "W_{\\tau_{\\lambda}} &= \\frac{1}{2} W_1 \\\\\n",
    "(1 - \\lambda) \\lambda^{\\tau_{\\lambda}-1} &= \\frac{1}{2} (1 - \\lambda) \\lambda^{1-1} \\\\\n",
    "\\lambda^{\\tau_{\\lambda}-1} &= \\frac{1}{2} \\\\\n",
    "\\tau_{\\lambda} - 1 &= log_{\\lambda} \\frac{1}{2} \\\\\n",
    "\\tau_{\\lambda} &= 1 - log_{\\lambda} 2, \\quad 0 \\lt \\lambda \\lt 1\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.3\n",
    "\n",
    "\n",
    "**Q**\n",
    "\n",
    "Some insight into how TD($\\lambda$) can closely approximate the offline $\\lambda$-return algorithm can be gained by seeing that the latter’s error term (in brackets in (12.4)) can be written as the sum of TD errors (12.6) for a single fixed $\\textbf{w}$. Show this, following the pattern of (6.6), and using the recursive relationship for the $\\lambda$-return you obtained in Exercise 12.1.\n",
    "\n",
    "**A**\n",
    "\n",
    "Equation 12.4 is:\n",
    "\n",
    "$$\n",
    "\\textbf{w}_{t+1} \\doteq \\textbf{w}_t + \\alpha [G_t^{\\lambda} - \\widehat{v}(S_t, \\textbf{w}_t)] \\nabla \\widehat{v}(S_t, \\textbf{w}_t), \\quad t = 0, ..., T - 1 \\tag{12.4}\n",
    "$$\n",
    "\n",
    "The error term in 12.4 is:\n",
    "\n",
    "$$\n",
    "G_t^{\\lambda} - \\widehat{v}(S_t, \\textbf{w}_t)\n",
    "$$\n",
    "\n",
    "Equation 12.6 (TD error) is:\n",
    "\n",
    "$$\n",
    "\\delta_t \\doteq R_{t+1} + \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}_t) - \\widehat{v}(S_t, \\textbf{w}_t) \\tag{12.6}\n",
    "$$\n",
    "\n",
    "The equation 6.6 is:\n",
    "\n",
    "\\begin{align*}\n",
    "G_t - V(S_t) &= R_{t+1} + \\gamma G_{t+1} - V(S_t) + \\gamma V(S_{t+1}) - \\gamma V(S_{t+1}) \\tag{from (3.9)} \\\\\n",
    "&= \\delta_t + \\gamma (G_{t+1} - V(S_{t+1})) \\\\\n",
    "&= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2 (G_{t+2} - V(S_{t+2})) \\\\\n",
    "&= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2 \\delta_{t+2} + ... + \\gamma^{T-t-1} \\delta_{T-1} + \\gamma^{T-t} (G_T - V(S_T)) \\\\\n",
    "&= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2 \\delta_{t+2} + ... + \\gamma^{T-t-1} \\delta_{T-1} + \\gamma^{T-t} (0 - 0) \\\\\n",
    "&= \\sum_{k=t}^{T-1} \\gamma^{k-t} \\delta_k \\tag{6.6}\n",
    "\\end{align*}\n",
    "\n",
    "So, for a single fixed $\\textbf{w}$ (so $\\textbf{w}_k = \\textbf{w}$ and $\\delta_t \\doteq R_{t+1} + \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}) - \\widehat{v}(S_t, \\textbf{w})$):\n",
    "\n",
    "\\begin{align*}\n",
    "G_t^{\\lambda} - \\widehat{v}(S_t, \\textbf{w}) &= R_{t+1} + (1 - \\lambda) \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}) + \\lambda \\gamma G_{t+1}^{\\lambda} - \\widehat{v}(S_t, \\textbf{w}) + \\lambda \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}) - \\lambda \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}) \\tag{from exercise 12.1} \\\\\n",
    "&= R_{t+1} + \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}) - \\lambda \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}) + \\lambda \\gamma G_{t+1}^{\\lambda} - \\widehat{v}(S_t, \\textbf{w}) + \\lambda \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}) - \\lambda \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}) \\\\\n",
    "&= [R_{t+1} + \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}) - \\widehat{v}(S_t, \\textbf{w})] + [\\lambda \\gamma G_{t+1}^{\\lambda} - \\lambda \\gamma \\widehat{v}(S_{t+1}, \\textbf{w})] \\\\\n",
    "&= \\delta_t + \\lambda \\gamma [G_{t+1}^{\\lambda} - \\widehat{v}(S_{t+1}, \\textbf{w})] \\\\\n",
    "&= \\delta_t + \\lambda \\gamma \\delta_{t+1} + \\lambda^2 \\gamma^2 [G_{t+2}^{\\lambda} - \\widehat{v}(S_{t+2}, \\textbf{w})] \\\\\n",
    "&= \\delta_t + \\lambda \\gamma \\delta_{t+1} + \\lambda^2 \\gamma^2 \\delta_{t+2} + ... + \\lambda^{T-t-1} \\gamma^{T-t-1} \\delta_{T-1} + \\lambda^{T-t} \\gamma^{T-t} [G_T^{\\lambda} - \\widehat{v}(S_T, \\textbf{w})] \\\\\n",
    "&= \\delta_t + \\lambda \\gamma \\delta_{t+1} + \\lambda^2 \\gamma^2 \\delta_{t+2} + ... + \\lambda^{T-t-1} \\gamma^{T-t-1} \\delta_{T-1} + \\lambda^{T-t} \\gamma^{T-t} [0 - 0] \\\\\n",
    "&= \\sum_{k=t}^{T-1} \\lambda^{k-t} \\gamma^{k-t} \\delta_k\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.4\n",
    "\n",
    "**Q**\n",
    "\n",
    "Use your result from the preceding exercise to show that, if the weight updates over an episode were computed on each step but not actually used to change the weights ($\\textbf{w}$ remained fixed), then the sum of TD($\\lambda$)’s weight updates would be the same as the sum of the offline $\\lambda$-return algorithm’s updates.\n",
    "\n",
    "**A**\n",
    "\n",
    "If $\\textbf{w}$ remained fixed, the result of the previous exercise can be applied, that is:\n",
    "\n",
    "$$\n",
    "G_t^{\\lambda} - \\widehat{v}(S_t, \\textbf{w}) = \\sum_{k=t}^{T-1} \\lambda^{k-t} \\gamma^{k-t} \\delta_k\n",
    "$$\n",
    "\n",
    "The TD($\\lambda$)’s weight update for a given time-step $t$ is:\n",
    "\n",
    "$$\n",
    "\\textbf{w}_{t+1} \\doteq \\textbf{w}_t + \\alpha \\delta_t \\textbf{z}_t \\tag{12.7}\n",
    "$$\n",
    "\n",
    "with:\n",
    "\n",
    "\\begin{align*}\n",
    "\\textbf{z}_{-1} &\\doteq \\textbf{0}, \\\\\n",
    "\\textbf{z}_t &\\doteq \\gamma \\lambda \\textbf{z}_{t-1} + \\nabla \\widehat{v}(S_t, \\textbf{w}_t), \\quad 0 \\leq t \\leq T \\tag{12.5}\n",
    "\\end{align*}\n",
    "\n",
    "The definition of $\\textbf{z}_t$ can be extended to:\n",
    "\n",
    "\\begin{align*}\n",
    "\\textbf{z}_t &\\doteq \\gamma \\lambda \\textbf{z}_{t-1} + \\nabla \\widehat{v}(S_t, \\textbf{w}_t) \\\\\n",
    "&= \\gamma^{t+1} \\lambda^{t+1} \\textbf{z}_{-1} + \\gamma^t \\lambda^t \\nabla \\widehat{v}(S_0, \\textbf{w}_0) + ... + \\gamma \\lambda \\nabla \\widehat{v}(S_{t-1}, \\textbf{w}_{t-1}) + \\nabla \\widehat{v}(S_t, \\textbf{w}_t) \\\\\n",
    "&= \\gamma^t \\lambda^t \\nabla \\widehat{v}(S_0, \\textbf{w}_0) + ... + \\gamma \\lambda \\nabla \\widehat{v}(S_{t-1}, \\textbf{w}_{t-1}) + \\nabla \\widehat{v}(S_t, \\textbf{w}_t) \\\\\n",
    "&= \\sum_{k=0}^t \\gamma^{t-k} \\lambda^{t-k} \\nabla \\widehat{v}(S_k, \\textbf{w}_k) \\tag{a2}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "The offline $\\lambda$-return algorithm’s update is:\n",
    "\n",
    "$$\n",
    "\\textbf{w}_{t+1} \\doteq \\textbf{w}_t + \\alpha [G_t^{\\lambda} - \\widehat{v}(S_t, \\textbf{w}_t)] \\nabla \\widehat{v}(S_t, \\textbf{w}_t), \\quad t = 0, ..., T - 1 \\tag{12.4}\n",
    "$$\n",
    "\n",
    "The sum of the offline $\\lambda$-return algorithm’s updates is:\n",
    "\n",
    "$$\n",
    "\\sum_{t = 0}^{T-1} [\\textbf{w}_{t+1} - \\textbf{w}_t] = \\sum_{t = 0}^{T-1} \\alpha [G_t^{\\lambda} - \\widehat{v}(S_t, \\textbf{w}_t)] \\nabla \\widehat{v}(S_t, \\textbf{w}_t)\n",
    "$$\n",
    "\n",
    "The sum of the TD($\\lambda$)’s weight updates is:\n",
    "\n",
    "\\begin{align*}\n",
    "\\sum_{t = 0}^{T-1} [\\textbf{w}_{t+1} - \\textbf{w}_t] &= \\sum_{t = 0}^{T-1} \\alpha \\delta_t \\textbf{z}_t \\\\\n",
    "&= \\sum_{t = 0}^{T-1} \\alpha \\delta_t \\sum_{k=0}^t \\gamma^{t-k} \\lambda^{t-k} \\nabla \\widehat{v}(S_k, \\textbf{w}) \\tag{from a2} \\\\\n",
    "&= \\sum_{t = 0}^{T-1} \\alpha \\nabla \\widehat{v}(S_t, \\textbf{w}) \\sum_{k=t}^{T-1} \\gamma^{k-t} \\lambda^{k-t} \\delta_k \\tag{a3, explained below} \\\\\n",
    "&= \\sum_{t = 0}^{T-1} \\alpha [G_t^{\\lambda} - \\widehat{v}(S_t, \\textbf{w})] \\nabla \\widehat{v}(S_t, \\textbf{w}) \\tag{from exercise 12.3} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "This proves that as long as the weights aren't updated during the episode, the sum of the TD($\\lambda$)’s weight updates would be the same as the sum of the offline $\\lambda$-return algorithm’s updates.\n",
    "\n",
    "*Note:* For any functions $f$, $g$ and $h$ that accept one, one and two integer parameters in $[0, T - 1]$, respectively, we have:\n",
    "\n",
    "\\begin{align*}\n",
    "\\sum_{t = 0}^{T-1} f(t) \\sum_{k=0}^t g(k) h(t, k) &= \\left[f(0) \\sum_{k=0}^0 g(k) h(0, k) \\right] + \\left[f(1) \\sum_{k=0}^1 g(k) h(1, k)\\right] + ... + \\left[f(T-1) \\sum_{k=0}^{T-1} g(k) h(T-1, k)\\right] \\\\\n",
    "&= [(f(0) g(0) h(0, 0))] \\\\\n",
    "&+ [(f(1) g(0) h(1, 0)) + (f(1) g(1) h(1, 1))] \\\\\n",
    "&+ ... \\\\\n",
    "&+ [(f(T-1) g(0) h(T-1, 0)) + (f(T-1) g(1) h(T-1, 1)) + ... + (f(T-1) g(T-1) h(T-1, T-1))] \\\\\n",
    "&= g(0) [(f(0) h(0, 0)) + (f(1) h(1, 0)) + ... + (f(T-1) h(T-1, 0))] \\\\\n",
    "&+ g(1) [(f(1) h(1, 1)) + (f(2) h(2, 1)) + ... + (f(T-1) h(T-1, 1))] \\\\\n",
    "&+ ... \\\\\n",
    "&+ g(T-1) [(f(T-1) h(T-1, T-1))] \\\\\n",
    "&= \\left[g(0) \\sum_{k=0}^{T-1} f(k) h(k, 0) \\right] + \\left[g(1) \\sum_{k=1}^{T-1} f(k) h(k, 1)\\right] + ... + \\left[g(T-1) \\sum_{k=T-1}^{T-1} f(k) h(k, T-1)\\right] \\\\\n",
    "&= \\sum_{t = 0}^{T-1} g(t) \\sum_{k=t}^{T-1} f(k) h(k, t)\n",
    "\\end{align*}\n",
    "\n",
    "Making $f(t) = \\alpha \\delta_t$, $g(k) = \\nabla \\widehat{v}(S_k, \\textbf{w})$ and $h(t, k) = \\gamma^{t-k} \\lambda^{t-k}$ we have:\n",
    "\n",
    "$$\n",
    "\\sum_{t = 0}^{T-1} \\alpha \\delta_t \\sum_{k=0}^t \\gamma^{t-k} \\lambda^{t-k} \\nabla \\widehat{v}(S_k, \\textbf{w}) = \\sum_{t = 0}^{T-1} \\alpha \\nabla \\widehat{v}(S_t, \\textbf{w}) \\sum_{k=t}^{T-1} \\gamma^{k-t} \\lambda^{k-t} \\delta_k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.5\n",
    "\n",
    "**Q**\n",
    "\n",
    "Several times in this book (often in exercises) we have established that returns can be written as sums of TD errors if the value function is held constant. Why is (12.10) another instance of this? Prove (12.10).\n",
    "\n",
    "**A**\n",
    "\n",
    "Equation 12.10 is:\n",
    "\n",
    "$$\n",
    "G_{t:t+k}^{\\lambda} = \\widehat{v}(S_t, \\textbf{w}_{t-1}) + \\sum_{i=t}^{t+k-1} (\\gamma \\lambda)^{i-t} \\delta_i' \\tag{12.10}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\delta_t' \\doteq R_{t+1} + \\gamma \\widehat{v}(S_{t+1}, \\textbf{w}_t) - \\widehat{v}(S_t, \\textbf{w}_{t-1})\n",
    "$$\n",
    "\n",
    "The original equation, 12.9, is:\n",
    "\n",
    "$$\n",
    "G_{t:h}^{\\lambda} \\doteq (1 - \\lambda) \\sum_{n=1}^{h-t-1} \\lambda^{n-1} G_{t:t+n} + \\lambda^{h-t-1} G_{t:h}, \\quad 0 \\leq t \\lt h \\leq T \\tag{12.9}\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "G_{t:t+n} \\doteq R_{t+1} + \\gamma R_{t+2} + ... + \\gamma^{n-1} R_{t+n} + \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}_{t+n-1}), \\quad 0 \\leq t \\leq T - n \\tag{12.1}\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "G_{t:t+n} \\doteq \\sum_{k=0}^{n-1} \\gamma^k R_{t+k+1} + \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}_{t+n-1}), \\quad 0 \\leq t \\leq T - n\n",
    "$$\n",
    "\n",
    "Also, consider the following:\n",
    "\n",
    "$$\n",
    "(1 - \\lambda) \\sum_{n=a}^b \\lambda^{n-1} = (1 - \\lambda) \\frac{\\lambda^{a-1} - \\lambda^b}{1 - \\lambda} = \\lambda^{a-1} - \\lambda^b \\tag{a4}\n",
    "$$\n",
    "\n",
    "If the value function is held constant, then $\\textbf{w}_t = \\textbf{w}$ for any $t$, so, starting from equation 12.9, we have (making $h = t + k$):\n",
    "\n",
    "\\begin{align*}\n",
    "G_{t:t+k}^{\\lambda} &\\doteq (1 - \\lambda) \\sum_{n=1}^{k-1} \\lambda^{n-1} G_{t:t+n} + \\lambda^{k-1} G_{t:t+k} \\\\\n",
    "\n",
    "&= (1 - \\lambda) \\sum_{n=1}^{k-1} \\lambda^{n-1} \\left[ \\sum_{q=0}^{n-1} \\gamma^q R_{t+q+1} + \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}) \\right] + \\lambda^{k-1} \\left[ \\sum_{q=0}^{k-1} \\gamma^q R_{t+q+1} + \\gamma^k \\widehat{v}(S_{t+k}, \\textbf{w}) \\right] \\\\\n",
    "\n",
    "&= (1 - \\lambda) \\sum_{n=1}^{k-1} \\lambda^{n-1} \\left[ \\sum_{q=0}^{n-1} \\gamma^q R_{t+q+1} \\right] + (1 - \\lambda) \\sum_{n=1}^{k-1} \\lambda^{n-1} \\left[ \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}) \\right] + \\lambda^{k-1} \\left[ \\sum_{q=0}^{k-1} \\gamma^q R_{t+q+1} \\right] + \\lambda^{k-1} \\left[ \\gamma^k \\widehat{v}(S_{t+k}, \\textbf{w}) \\right] \\\\\n",
    "\n",
    "&= (1 - \\lambda) \\sum_{q=0}^{k-2} \\left[ \\sum_{n=q+1}^{k-1} \\lambda^{n-1} \\right] \\gamma^q R_{t+q+1} + (1 - \\lambda) \\sum_{n=1}^{k-1} \\lambda^{n-1} \\left[ \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}) \\right] + \\lambda^{k-1} \\left[ \\sum_{q=0}^{k-1} \\gamma^q R_{t+q+1} \\right] + \\lambda^{k-1} \\left[ \\gamma^k \\widehat{v}(S_{t+k}, \\textbf{w}) \\right] \\tag{see exercise 12.4} \\\\\n",
    "\n",
    "&= \\left[ \\left( \\sum_{q=0}^{k-2} \\left[ (1 - \\lambda) \\sum_{n=q+1}^{k-1} \\lambda^{n-1} \\right] \\gamma^q R_{t+q+1} \\right) + \\left( \\lambda^{k-1} \\left[ \\sum_{q=0}^{k-1} \\gamma^q R_{t+q+1} \\right] \\right) \\right] + (1 - \\lambda) \\sum_{n=1}^{k-1} \\lambda^{n-1} \\left[ \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}) \\right] + \\lambda^{k-1} \\left[ \\gamma^k \\widehat{v}(S_{t+k}, \\textbf{w}) \\right] \\\\\n",
    "\n",
    "&= \\left[ \\left( \\sum_{q=0}^{k-2} \\left[ \\lambda^q - \\lambda^{k-1} \\right] \\gamma^q R_{t+q+1} \\right) + \\left( \\lambda^{k-1} \\left[ \\sum_{q=0}^{k-2} \\gamma^q R_{t+q+1} \\right] + \\lambda^{k-1} \\gamma^{k-1} R_{t+k} \\right) \\right] + (1 - \\lambda) \\sum_{n=1}^{k-1} \\lambda^{n-1} \\left[ \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}) \\right] + \\lambda^{k-1} \\left[ \\gamma^k \\widehat{v}(S_{t+k}, \\textbf{w}) \\right] \\tag{from a4} \\\\\n",
    "\n",
    "&= \\left[ \\left( \\sum_{q=0}^{k-2} \\lambda^q \\gamma^q R_{t+q+1} \\right) - \\left( \\sum_{q=0}^{k-2} \\lambda^{k-1} \\gamma^q R_{t+q+1} \\right) + \\left( \\sum_{q=0}^{k-2} \\lambda^{k-1} \\gamma^q R_{t+q+1} \\right) + \\left( \\lambda^{k-1} \\gamma^{k-1} R_{t+k} \\right) \\right] + (1 - \\lambda) \\sum_{n=1}^{k-1} \\lambda^{n-1} \\left[ \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}) \\right] + \\lambda^{k-1} \\left[ \\gamma^k \\widehat{v}(S_{t+k}, \\textbf{w}) \\right] \\\\\n",
    "\n",
    "&= \\left[ \\left( \\sum_{q=0}^{k-2} \\lambda^q \\gamma^q R_{t+q+1} \\right) + \\left( \\lambda^{k-1} \\gamma^{k-1} R_{t+k} \\right) \\right] + \\left[ (1 - \\lambda) \\sum_{n=1}^{k-1} \\lambda^{n-1} \\left[ \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}) \\right] + \\lambda^{k-1} \\left[ \\gamma^k \\widehat{v}(S_{t+k}, \\textbf{w}) \\right] \\right] \\\\\n",
    "\n",
    "&= \\left[ \\sum_{q=0}^{k-1} \\lambda^q \\gamma^q R_{t+q+1} \\right] + \\left[ \\left( \\sum_{n=1}^{k-1} \\lambda^{n-1} \\left[ \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}) \\right] \\right) - \\left( \\lambda \\sum_{n=1}^{k-1} \\lambda^{n-1} \\left[ \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}) \\right] \\right) + \\left( \\lambda^{k-1} \\left[ \\gamma^k \\widehat{v}(S_{t+k}, \\textbf{w}) \\right] \\right) \\right] \\\\\n",
    "\n",
    "&= \\left[ \\sum_{n=1}^k \\lambda^{n-1} \\gamma^{n-1} R_{t+n} \\right] + \\left[ \\sum_{n=1}^k \\lambda^{n-1} \\left[ \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}) \\right] \\right] - \\left[ \\lambda \\sum_{n=1}^{k-1} \\lambda^{n-1} \\left[ \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}) \\right] \\right] \\\\\n",
    "\n",
    "&= \\left[ \\sum_{n=1}^k \\lambda^{n-1} \\gamma^{n-1} [R_{t+n} + \\gamma \\widehat{v}(S_{t+n}, \\textbf{w})] \\right] - \\left[ \\left( \\sum_{n=1}^{k-1} \\lambda^n \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}) \\right) + (\\lambda^0 \\gamma^0 \\widehat{v}(S_{t+0}, \\textbf{w})) - (\\lambda^0 \\gamma^0 \\widehat{v}(S_{t+0}, \\textbf{w})) \\right] \\\\\n",
    "\n",
    "&= \\left[ \\sum_{n=1}^k \\lambda^{n-1} \\gamma^{n-1} [R_{t+n} + \\gamma \\widehat{v}(S_{t+n}, \\textbf{w})] \\right] - \\left[ \\left( \\sum_{n=0}^{k-1} \\lambda^n \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}) \\right) - (\\widehat{v}(S_t, \\textbf{w})) \\right] \\\\\n",
    "\n",
    "&= \\widehat{v}(S_t, \\textbf{w}) + \\left[ \\sum_{n=1}^k \\lambda^{n-1} \\gamma^{n-1} [R_{t+n} + \\gamma \\widehat{v}(S_{t+n}, \\textbf{w})] \\right] - \\left[ \\sum_{n=0}^{k-1} \\lambda^n \\gamma^n \\widehat{v}(S_{t+n}, \\textbf{w}) \\right] \\\\\n",
    "\n",
    "&= \\widehat{v}(S_t, \\textbf{w}) + \\left[ \\sum_{n=1}^k \\lambda^{n-1} \\gamma^{n-1} [R_{t+n} + \\gamma \\widehat{v}(S_{t+n}, \\textbf{w})] \\right] - \\left[ \\sum_{n=1}^k \\lambda^{n-1} \\gamma^{n-1} \\widehat{v}(S_{t+n-1}, \\textbf{w}) \\right] \\\\\n",
    "\n",
    "&= \\widehat{v}(S_t, \\textbf{w}) + \\left[ \\sum_{n=1}^k \\lambda^{n-1} \\gamma^{n-1} [R_{t+n} + \\gamma \\widehat{v}(S_{t+n}, \\textbf{w}) - \\widehat{v}(S_{t+n-1}, \\textbf{w})] \\right] \\\\\n",
    "\n",
    "&= \\widehat{v}(S_t, \\textbf{w}) + \\left[ \\sum_{n=1}^k \\lambda^{n-1} \\gamma^{n-1} \\delta_{t+n-1}' \\right]\n",
    "\\end{align*}\n",
    "\n",
    "Readjusting the indices, from $t$ to $t+k-1$, replacing the occurences of $n$ by $i-t+1$ (the same corresponding $k$ terms):\n",
    "\n",
    "$$\n",
    "G_{t:t+k}^{\\lambda} = \\widehat{v}(S_t, \\textbf{w}) + \\left[ \\sum_{i=t}^{t+k-1} \\lambda^{i-t} \\gamma^{i-t} \\delta_i' \\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.6\n",
    "\n",
    "**Q**\n",
    "\n",
    "Modify the pseudocode for Sarsa($\\lambda$) to use dutch traces (12.11) without the other distinctive features of a true online algorithm. Assume linear function approximation and binary features.\n",
    "\n",
    "**A**\n",
    "\n",
    "The True Online TD pseudocode provided is:\n",
    "\n",
    "> Input: the policy $\\pi$ to be evaluated<br/>\n",
    "> Input: a feature function $\\textbf{x} : \\mathcal{S}^+ \\to \\mathbb{R}^d$ such that $\\textbf{x}(terminal, \\cdot) = \\textbf{0}$<br/>\n",
    "> Algorithm parameters: step size $\\alpha > 0$, trace decay rate $\\lambda \\in [0, 1]$<br/>\n",
    "> Initialize value-function weights $\\textbf{w} \\in \\mathbb{R}^d$ (e.g., $\\textbf{w} = \\textbf{0}$)<br/>\n",
    ">\n",
    "> Loop for each episode:<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;Initialize state and obtain initial feature vector $\\textbf{x}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;$\\textbf{z} \\gets \\textbf{0} \\quad$ (a d-dimensional vector)<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;$V_{old} \\gets 0 \\quad$ (a temporary scalar variable)<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;Loop for each step of episode:<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Choose $A \\sim \\pi$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Take action A, observe R, $\\textbf{x'}$ (feature vector of the next state)<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$V \\gets \\textbf{w}^T \\textbf{x}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$V' \\gets \\textbf{w}^T \\textbf{x'}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\delta \\gets R + \\gamma V' - V$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\textbf{z} \\gets \\gamma \\lambda \\textbf{z} + (1 - \\alpha \\gamma \\lambda \\textbf{z}^T \\textbf{x}) \\textbf{x}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\textbf{w} \\gets \\textbf{w} + \\alpha (\\delta + V - V_{old}) \\textbf{z} - \\alpha (V - V_{old}) \\textbf{x}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$V_{old} \\gets V'$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\textbf{x} \\gets \\textbf{x'}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;until $\\textbf{x'} = \\textbf{0}$ (signaling arrival at a terminal state)\n",
    "\n",
    "The pseudocode provided for Sarsa($\\lambda$) with binary features and linear function approximation for estimating $\\textbf{w}^T \\textbf{x} \\approx q_{\\pi} or q_*$ is:\n",
    "\n",
    "> Input: a function $\\mathcal{F}(s, a)$ returning a set of (indices of) active features for $s$, $a$<br/>\n",
    "> Input: the policy $\\pi$ (if estimating $q_{\\pi}$)<br/>\n",
    "> Algorithm parameters: step size $\\alpha > 0$, trace decay rate $\\lambda \\in [0, 1]$<br/>\n",
    "> Initialize $\\textbf{w} = (w_1, ..., w_d)^T \\in \\mathbb{R}^d$ (e.g., $\\textbf{w} = \\textbf{0}$), $\\textbf{z} = (z_1, ..., z_d)^T \\in \\mathbb{R}^d$<br/>\n",
    ">\n",
    "> Loop for each episode:<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;Initialize S<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;Choose $A \\sim \\pi(\\cdot | S)$ or $\\epsilon$-greedy according to $\\widehat{q}(S, \\cdot, \\textbf{w})$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;$\\textbf{z} \\gets \\textbf{0}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;Loop for each step of episode:<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Take action A, observe R, S'<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\delta \\gets R$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Loop for $i$ in $\\mathcal{F}(S, A)$:<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\delta \\gets \\delta - w_i$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$z_i \\gets z_i + 1 \\quad$ (accumulating traces)<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;or $z_i \\gets 1 \\quad$ (replacing traces)<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If S' is terminal then:<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\textbf{w} \\gets \\textbf{w} + \\alpha \\delta \\textbf{z}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Go to next episode<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Choose $A' \\sim \\pi(\\cdot | S')$ or near greedily $\\sim \\widehat{q}(S', \\cdot, \\textbf{w})$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Loop for $i$ in $\\mathcal{F}(S', A')$: $\\delta \\gets \\delta + \\gamma w_i$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\textbf{w} \\gets \\textbf{w} \\alpha \\delta \\textbf{z}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\textbf{z} \\gets \\gamma \\lambda \\textbf{z}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$S \\gets S'; A \\gets A'$<br/>\n",
    "\n",
    "Equation 12.11 is:\n",
    "\n",
    "$$\n",
    "\\textbf{z}_t \\doteq \\gamma \\lambda \\textbf{z}_{t-1} + (1 - \\alpha \\gamma \\lambda \\textbf{z}_{t-1}^T \\textbf{x}_t) \\textbf{x}_t \\tag{12.11}\n",
    "$$\n",
    "\n",
    "For this example, $\\textbf{x}_t = \\mathcal{F}(S_t, A_t)$, so the equation becomes:\n",
    "\n",
    "$$\n",
    "\\textbf{z}_t \\doteq \\gamma \\lambda \\textbf{z}_{t-1} + (1 - \\alpha \\gamma \\lambda \\textbf{z}_{t-1}^T \\mathcal{F}(S_t, A_t)) \\mathcal{F}(S_t, A_t)\n",
    "$$\n",
    "\n",
    "It's important to note that the vector row $\\textbf{z}_{t-1}^T$ multiplied by the vector column $\\mathcal{F}(S_t, A_t)$ gives a scalar, so the entire term $1 - \\alpha \\gamma \\lambda \\textbf{z}_{t-1}^T \\mathcal{F}(S_t, A_t)$ is a scalar, which will be represented by the variable $\\phi$ in the pseudocode ($\\phi_0 = (1 - 0) = 1$). When the trace is being accumulated, this will be the weight that is multiplied by the features vector.\n",
    "\n",
    "Also, note that except for $\\textbf{z}_{-1} = \\textbf{0}$, the value of $\\textbf{z}$ is partially defined at the end of the previous episode, specifically the left term ($\\gamma \\lambda \\textbf{z}$), while the right term is defined in the current episode. This right term depends on $\\phi$, which depends on the previous value of $\\textbf{z}$, so the value of $\\phi$ used in an episode must be defined in the previous episode, before $\\textbf{z} \\gets \\gamma \\lambda \\textbf{z}$ (with $\\phi_0 = 1$, so that $\\textbf{z}_0 = \\gamma \\lambda \\textbf{z}_{-1} + \\phi_0 \\textbf{x}_0 = 0 + 1 \\cdot \\textbf{x}_0 = \\textbf{x}_0$).\n",
    "\n",
    "The pseudocode for Sarsa($\\lambda$) with dutch traces (12.11) without the other distinctive features of a true online algorithm is defined below:\n",
    "\n",
    "> Input: a function $\\mathcal{F}(s, a)$ returning a set of (indices of) active features for $s$, $a$<br/>\n",
    "> Input: the policy $\\pi$ (if estimating $q_{\\pi}$)<br/>\n",
    "> Algorithm parameters: step size $\\alpha > 0$, trace decay rate $\\lambda \\in [0, 1]$<br/>\n",
    "> Initialize $\\textbf{w} = (w_1, ..., w_d)^T \\in \\mathbb{R}^d$ (e.g., $\\textbf{w} = \\textbf{0}$), $\\textbf{z} = (z_1, ..., z_d)^T \\in \\mathbb{R}^d$<br/>\n",
    ">\n",
    "> Loop for each episode:<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;Initialize S<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;Choose $A \\sim \\pi(\\cdot | S)$ or $\\epsilon$-greedy according to $\\widehat{q}(S, \\cdot, \\textbf{w})$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;$\\textbf{z} \\gets \\textbf{0}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;$\\phi \\gets 1$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;Loop for each step of episode:<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Take action A, observe R, S'<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\delta \\gets R$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Loop for $i$ in $\\mathcal{F}(S, A)$:<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\delta \\gets \\delta - w_i$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$z_i \\gets z_i + \\phi \\quad$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If S' is terminal then:<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\textbf{w} \\gets \\textbf{w} + \\alpha \\delta \\textbf{z}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Go to next episode<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Choose $A' \\sim \\pi(\\cdot | S')$ or near greedily $\\sim \\widehat{q}(S', \\cdot, \\textbf{w})$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Loop for $i$ in $\\mathcal{F}(S', A')$: $\\delta \\gets \\delta + \\gamma w_i$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\textbf{w} \\gets \\textbf{w} \\alpha \\delta \\textbf{z}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$s_{dot} = 0$ (temporary variable to get the value of $\\textbf{z}_{t-1}^T \\textbf{x}_t$, with $\\textbf{x}_t$ being 1 for the indices returned by $\\mathcal{F}(S', A')$, and 0 otherwise)<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Loop for $i$ in $\\mathcal{F}(S', A')$:<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$s_{dot} \\gets s_{dot} + z_i$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\phi \\gets 1 - \\alpha \\gamma \\lambda s_{dot}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\textbf{z} \\gets \\gamma \\lambda \\textbf{z}$<br/>\n",
    ">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$S \\gets S'; A \\gets A'$<br/>\n",
    "\n",
    "The elegibility trace ($\\textbf{z}$) would be defined with $z_i \\gets z_i + \\phi \\cdot x_i$ for each index, but the features are binary and $\\mathcal{F}(S, A)$ is the set of indices $i$ in which $x_i = 1$ for the given state and action (all other indices $j$ have $x_j = 0$), so $z_i + \\phi \\cdot x_i = z_i + \\phi$ (the entire loop is equivalent to $\\textbf{z} \\gets \\textbf{z} + \\phi \\cdot \\textbf{x}$, with $\\textbf{z}$ already defined at the end of the previous episode as $\\textbf{z} \\gets \\gamma \\lambda \\textbf{z}$, so this is the update provided by 12.11). Similarly, in the later part of the pseudocode, $s_{dot} \\gets s_{dot} + z_i$ because $s_{dot} + z_i x_i = s_{dot} + z_i$ for the indices $i$ given by $\\mathcal{F}(S', A')$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.7\n",
    "\n",
    "**Q**\n",
    "\n",
    "Generalize the three recursive equations above to their truncated versions, defining $G_{t:h}^{\\lambda s}$ and $G_{t:h}^{\\lambda a}$.\n",
    "\n",
    "**A**\n",
    "\n",
    "The 3 equations are:\n",
    "\n",
    "$$\n",
    "G_t^{\\lambda s} \\doteq R_{t+1} + \\gamma_{t+1} ((1 - \\lambda_{t+1}) \\widehat{v}(S_{t+1}, \\textbf{w}_t) + \\lambda_{t+1} G_{t+1}^{\\lambda s}) \\tag{12.18}\n",
    "$$\n",
    "\n",
    "$$\n",
    "G_t^{\\lambda a} \\doteq R_{t+1} + \\gamma_{t+1} ((1 - \\lambda_{t+1}) \\widehat{q}(S_{t+1}, A_{t+1}, \\textbf{w}_t) + \\lambda_{t+1} G_{t+1}^{\\lambda a}) \\tag{12.19}\n",
    "$$\n",
    "\n",
    "$$\n",
    "G_t^{\\lambda a} \\doteq R_{t+1} + \\gamma_{t+1} ((1 - \\lambda_{t+1}) \\overline{V}(S_{t+1}) + \\lambda_{t+1} G_{t+1}^{\\lambda a}) \\tag{12.20}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\overline{V}(a) \\doteq \\sum_a \\pi(a | s) \\widehat{q}(s, a, \\textbf{w}_t) \\tag{12.21}\n",
    "$$\n",
    "\n",
    "The original version $G_t^{\\lambda s}$ is equivalent to $G_{t:\\infty}^{\\lambda s}$, with the returns being used forever in the continuing case, or until the end of the episode in the episodic case. $G_{t:h}^{\\lambda s} = G_t^{\\lambda s}$ if $h \\geq T$, with:\n",
    "\n",
    "$$\n",
    "G_{t:h} \\doteq R_{t+1} + \\gamma R_{t+2} + ... + \\gamma^{n-1} R_{t+n} + \\gamma^n \\widehat{v}(S_h, \\textbf{w}_{h-1}) = \\sum_{k = 0}^{n-1} \\gamma^k R_{t+k+1} + \\gamma^n \\widehat{v}(S_h, \\textbf{w}_{h-1}), \\quad 0 \\leq t \\lt h \\leq T\n",
    "$$\n",
    "\n",
    "and corresponding cases for $\\widehat{q}(S_{t+1}, A_{t+1}, \\textbf{w}_t)$ and $\\overline{V}(S_{t+1})$.\n",
    "\n",
    "Applying the same reasoning, we have at the end of the chain $G_{h:h}^{\\lambda s} = \\widehat{v}(S_h, \\textbf{w}_{h-1})$ and:\n",
    "\n",
    "$$\n",
    "G_{h-1:h}^{\\lambda s} \\doteq R_h + \\gamma_h ((1 - \\lambda_h) \\widehat{v}(S_h, \\textbf{w}_{h-1}) + \\lambda_h \\widehat{v}(S_h, \\textbf{w}_{h-1})) = R_h + \\gamma_h \\widehat{v}(S_h, \\textbf{w}_{h-1})\n",
    "$$\n",
    "\n",
    "which is TD(0) for that step, and by definition $G_T^{\\lambda s} = 0$. The same can be said for $G_{h-1:h}^{\\lambda a}$ (for $\\widehat{q}(S_h, A_h, \\textbf{w}_{h-1})$ and $\\overline{V}(S_h)$).\n",
    "\n",
    "Extending 12.18, we have:\n",
    "\n",
    "\\begin{align*}\n",
    "G_t^{\\lambda s} &\\doteq R_{t+1} + \\gamma_{t+1} ((1 - \\lambda_{t+1}) \\widehat{v}(S_{t+1}, \\textbf{w}_t) + \\lambda_{t+1} G_{t+1}^{\\lambda s}) \\\\\n",
    "\n",
    "&= [R_{t+1}] + [\\gamma_{t+1} (1 - \\lambda_{t+1}) \\widehat{v}(S_{t+1}, \\textbf{w}_t)] + \\gamma_{t+1} \\lambda_{t+1} G_{t+1}^{\\lambda s} \\\\\n",
    "\n",
    "&= [R_{t+1}] + [\\gamma_{t+1} (1 - \\lambda_{t+1}) \\widehat{v}(S_{t+1}, \\textbf{w}_t)] + \\gamma_{t+1} \\lambda_{t+1} [[R_{t+2}] + [\\gamma_{t+2} (1 - \\lambda_{t+2}) \\widehat{v}(S_{t+2}, \\textbf{w}_{t+1})] + \\gamma_{t+2} \\lambda_{t+2} G_{t+2}^{\\lambda s}] \\\\\n",
    "\n",
    "&= [R_{t+1} + \\gamma_{t+1} \\lambda_{t+1} R_{t+2}] + [\\gamma_{t+1} (1 - \\lambda_{t+1}) \\widehat{v}(S_{t+1}, \\textbf{w}_t)] + [\\gamma_{t+1} \\lambda_{t+1} \\gamma_{t+2} (1 - \\lambda_{t+2}) \\widehat{v}(S_{t+2}, \\textbf{w}_{t+1})] + \\gamma_{t+1} \\lambda_{t+1} \\gamma_{t+2} \\lambda_{t+2} G_{t+2}^{\\lambda s} \\\\\n",
    "\n",
    "&= \\sum_{k=t}^{t+1} \\left[ \\left( \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\right) (R_{k+1} + \\gamma_{k+1} (1 - \\lambda_{k+1}) \\widehat{v}(S_{k+1}, \\textbf{w}_k)) \\right] + \\left( \\prod_{i=t+1}^{t+2} \\gamma_i \\lambda_i \\right) G_{t+2}^{\\lambda s} \\\\\n",
    "\n",
    "&= \\sum_{k=t}^{h-1} \\left[ \\left( \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\right) (R_{k+1} + \\gamma_{k+1} (1 - \\lambda_{k+1}) \\widehat{v}(S_{k+1}, \\textbf{w}_k)) \\right] + \\left( \\prod_{i=t+1}^h \\gamma_i \\lambda_i \\right) G_h^{\\lambda s}\n",
    "\\end{align*}\n",
    "\n",
    "So:\n",
    "\n",
    "\\begin{align*}\n",
    "G_{t:h}^{\\lambda s} &= \\sum_{k=t}^{h-1} \\left[ \\left( \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\right) (R_{k+1} + \\gamma_{k+1} (1 - \\lambda_{k+1}) \\widehat{v}(S_{k+1}, \\textbf{w}_k)) \\right] + \\left( \\prod_{i=t+1}^h \\gamma_i \\lambda_i \\right) G_{h:h}^{\\lambda s} \\\\\n",
    "\n",
    "&= \\sum_{k=t}^{h-1} \\left[ \\left( \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\right) (R_{k+1} + \\gamma_{k+1} (1 - \\lambda_{k+1}) \\widehat{v}(S_{k+1}, \\textbf{w}_k)) \\right] + \\left( \\prod_{i=t+1}^h \\gamma_i \\lambda_i \\right) \\widehat{v}(S_h, \\textbf{w}_{h-1})\n",
    "\\end{align*}\n",
    "\n",
    "which is the recursion of $G_t^{\\lambda s}$ until $t = h$, in which case the estimated value is returned.\n",
    "\n",
    "Similarly:\n",
    "\n",
    "$$\n",
    "G_{t:h}^{\\lambda a} = \\sum_{k=t}^{h-1} \\left[ \\left( \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\right) (R_{k+1} + \\gamma_{k+1} (1 - \\lambda_{k+1}) \\widehat{q}(S_{k+1}, A_{k+1}, \\textbf{w}_k)) \\right] + \\left( \\prod_{i=t+1}^h \\gamma_i \\lambda_i \\right) \\widehat{q}(S_h, A_k, \\textbf{w}_{h-1})\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "G_{t:h}^{\\lambda a} = \\sum_{k=t}^{h-1} \\left[ \\left( \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\right) (R_{k+1} + \\gamma_{k+1} (1 - \\lambda_{k+1}) \\overline{V}(S_{k+1})) \\right] + \\left( \\prod_{i=t+1}^h \\gamma_i \\lambda_i \\right) \\overline{V}(S_h)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.8\n",
    "\n",
    "**Q**\n",
    "\n",
    "Prove that (12.24) becomes exact if the value function does not change. To save writing, consider the case of t = 0, and use the notation $V_k \\doteq \\widehat{v}(S_k, \\textbf{w})$.\n",
    "\n",
    "**A**\n",
    "\n",
    "Equation 12.24 is:\n",
    "\n",
    "$$\n",
    "G_t^{\\lambda s} \\approx V_t + \\rho_t \\sum_{k=t}^{\\infty} \\delta_k^s \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\tag{12.24}\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "\\delta_t^s \\doteq R_{t+1} + \\gamma_{t+1} V_{t+1} - V_t \\tag{12.23}\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "\\begin{align*}\n",
    "G_t^{\\lambda s} &\\doteq \\rho_t (R_{t+1} + \\gamma_{t+1} ((1 - \\lambda_{t+1}) V_{t+1} + \\lambda_{t+1} G_{t+1}^{\\lambda s})) + (1 - \\rho_t) V_t \\tag{12.22} \\\\\n",
    "\n",
    "&= [\\rho_t R_{t+1}] + [\\rho_t \\gamma_{t+1} (1 - \\lambda_{t+1}) V_{t+1}] + [V_t - \\rho_t V_t] + \\rho_t \\gamma_{t+1} \\lambda_{t+1} G_{t+1}^{\\lambda s} \\\\\n",
    "\n",
    "&= V_t + \\rho_t [R_{t+1} + \\gamma_{t+1} V_{t+1} - \\gamma_{t+1} \\lambda_{t+1} V_{t+1} - V_t] + \\rho_t \\gamma_{t+1} \\lambda_{t+1} G_{t+1}^{\\lambda s} \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\delta_t^s - \\rho_t \\gamma_{t+1} \\lambda_{t+1} V_{t+1} + \\rho_t \\gamma_{t+1} \\lambda_{t+1} G_{t+1}^{\\lambda s} \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\delta_t^s + \\rho_t \\gamma_{t+1} \\lambda_{t+1} [G_{t+1}^{\\lambda s} - V_{t+1}] \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\delta_t^s + \\rho_t \\gamma_{t+1} \\lambda_{t+1} [(V_{t+1} + \\rho_{t+1} \\delta_{t+1}^s + \\rho_{t+1} \\gamma_{t+2} \\lambda_{t+2} [G_{t+2}^{\\lambda s} -  V_{t+2}]) - V_{t+1}] \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\delta_t^s + \\rho_t \\gamma_{t+1} \\lambda_{t+1} [\\rho_{t+1} \\delta_{t+1}^s + \\rho_{t+1} \\gamma_{t+2} \\lambda_{t+2} [G_{t+2}^{\\lambda s} -  V_{t+2}]] \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\delta_t^s + \\rho_t \\gamma_{t+1} \\lambda_{t+1} \\rho_{t+1} \\delta_{t+1}^s + \\rho_t \\gamma_{t+1} \\lambda_{t+1} \\rho_{t+1} \\gamma_{t+2} \\lambda_{t+2} [G_{t+2}^{\\lambda s} -  V_{t+2}] \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\left[\\delta_t^s + \\gamma_{t+1} \\lambda_{t+1} \\rho_{t+1} \\delta_{t+1}^s + \\gamma_{t+1} \\lambda_{t+1} \\rho_{t+1} \\gamma_{t+2} \\lambda_{t+2} [G_{t+2}^{\\lambda s} -  V_{t+2}] \\right] \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\left[ \\left( \\sum_{k=t}^{t+1} \\delta_k^s \\left[ \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\right] \\right) + \\left( \\prod_{i=t+1}^{t+2} \\gamma_i \\lambda_i \\right) \\left( \\prod_{i=t+1}^{t+2-1} \\rho_i \\right) (G_{t+2}^{\\lambda s} - V_{t+2}) \\right] \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\left[ \\left( \\sum_{k=t}^{h-1} \\delta_k^s \\left[ \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\right] \\right) + \\left( \\prod_{i=t+1}^h \\gamma_i \\lambda_i \\right) \\left( \\prod_{i=t+1}^{h-1} \\rho_i \\right) (G_h^{\\lambda s} - V_h) \\right] \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Considering that $G_t^{\\lambda s} = \\operatorname*{lim}_{h \\to \\infty} G_{t:h}^{\\lambda s}$ and that $G_{h:h}^{\\lambda s} = V_h$ (see Exercise 12.7), we have:\n",
    "\n",
    "\\begin{align*}\n",
    "G_t^{\\lambda s} &= \\operatorname*{lim}_{h \\to \\infty} G_{t:h}^{\\lambda s} \\\\\n",
    "\n",
    "&= \\operatorname*{lim}_{h \\to \\infty} \\left[ V_t + \\rho_t \\left[ \\left( \\sum_{k=t}^{h-1} \\delta_k^s \\left[ \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\right] \\right) + \\left( \\prod_{i=t+1}^h \\gamma_i \\lambda_i \\right) \\left( \\prod_{i=t+1}^{h-1} \\rho_i \\right) (G_{h:h}^{\\lambda s} - V_h) \\right] \\right] \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\sum_{k=t}^{\\infty} \\delta_k^s \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i + \\left[ \\operatorname*{lim}_{h \\to \\infty} \\rho_t \\left( \\prod_{i=t+1}^h \\gamma_i \\lambda_i \\right) \\left( \\prod_{i=t+1}^{h-1} \\rho_i \\right) \\left( G_{h:h} - V_h \\right) \\right] \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\sum_{k=t}^{\\infty} \\delta_k^s \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i + \\left[ \\operatorname*{lim}_{h \\to \\infty} \\rho_t \\left( \\prod_{i=t+1}^h \\gamma_i \\lambda_i \\right) \\left( \\prod_{i=t+1}^{h-1} \\rho_i \\right) \\left( V_h - V_h \\right) \\right] \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\sum_{k=t}^{\\infty} \\delta_k^s \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i + 0 \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\sum_{k=t}^{\\infty} \\delta_k^s \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i\n",
    "\\end{align*}\n",
    "\n",
    "This was already proven for any t, so it satisfies for $t = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.9\n",
    "\n",
    "**Q**\n",
    "\n",
    "The truncated version of the general off-policy return is denoted $G_{t:h}^{\\lambda s}$. Guess the correct equation, based on (12.24).\n",
    "\n",
    "**A**\n",
    "\n",
    "As it was already demonstrated in Exercise 12.8, expanding $G_t^{\\lambda s}$ until $t = h$:\n",
    "\n",
    "$$\n",
    "G_t^{\\lambda s} = V_t + \\rho_t \\left[ \\left( \\sum_{k=t}^{h-1} \\delta_k^s \\left[ \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\right] \\right) + \\left( \\prod_{i=t+1}^h \\gamma_i \\lambda_i \\right) \\left( \\prod_{i=t+1}^{h-1} \\rho_i \\right) (G_h^{\\lambda s} - V_h) \\right]\n",
    "$$\n",
    "\n",
    "As a result:\n",
    "\n",
    "\\begin{align*}\n",
    "G_{t:h}^{\\lambda s} &= V_t + \\rho_t \\left[ \\left( \\sum_{k=t}^{h-1} \\delta_k^s \\left[ \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\right] \\right) + \\left( \\prod_{i=t+1}^h \\gamma_i \\lambda_i \\right) \\left( \\prod_{i=t+1}^{h-1} \\rho_i \\right) (G_{h:h}^{\\lambda s} - V_h) \\right] \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\left[ \\left( \\sum_{k=t}^{h-1} \\delta_k^s \\left[ \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\right] \\right) + \\left( \\prod_{i=t+1}^h \\gamma_i \\lambda_i \\right) \\left( \\prod_{i=t+1}^{h-1} \\rho_i \\right) (V_h - V_h) \\right] \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\left[ \\left( \\sum_{k=t}^{h-1} \\delta_k^s \\left[ \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\right] \\right) + 0 \\right] \\\\\n",
    "\n",
    "&= V_t + \\rho_t \\sum_{k=t}^{h-1} \\delta_k^s \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.10\n",
    "\n",
    "**Q**\n",
    "\n",
    "Prove that (12.27) becomes exact if the value function does not change. To save writing, consider the case of t = 0, and use the notation $Q_k = \\widehat{q}(S_k, A_k, \\textbf{w})$. Hint: Start by writing out $\\delta_0^a$ and $G_0^{\\lambda a}$, then $G_0^{\\lambda a} - Q_0$.\n",
    "\n",
    "**A**\n",
    "\n",
    "Equation 12.27 is:\n",
    "\n",
    "$$\n",
    "G_t^{\\lambda a} \\approx Q_t + \\sum_{k=t}^{\\infty} \\delta_k^a \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\tag{12.27}\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "\\delta_t^a \\doteq R_{t+1} + \\gamma_{t+1} \\overline{V}_{t+1} - Q_t \\tag{12.28}\n",
    "$$\n",
    "\n",
    "The definition of $G_t^{\\lambda a}$ is:\n",
    "\n",
    "\\begin{align*}\n",
    "G_t^{\\lambda a} &\\doteq R_{t+1} + \\gamma_{t+1} ((1 - \\lambda_{t+1}) \\overline{V}_{t+1} + \\lambda_{t+1} [\\rho_{t+1} G_{t+1}^{\\lambda a} + \\overline{V}_{t+1} - \\rho_{t+1} Q_{t+1}]) \\\\\n",
    "&= R_{t+1} + \\gamma_{t+1} (\\overline{V}_{t+1} + \\lambda_{t+1} \\rho_{t+1} [G_{t+1}^{\\lambda a} - Q_{t+1}]) \\tag{12.26}\n",
    "\\end{align*}\n",
    "\n",
    "We have:\n",
    "\n",
    "$$\n",
    "\\delta_0^a \\doteq R_1 + \\gamma_1 \\overline{V}_1 - Q_0\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "\\begin{align*}\n",
    "G_0^{\\lambda a} - Q_0 &\\approx \\sum_{k=0}^{\\infty} \\delta_k^a \\prod_{i=1}^k \\gamma_i \\lambda_i \\rho_i \\\\\n",
    "\n",
    "&= \\left[ \\delta_0^a \\prod_{i=1}^0 \\gamma_i \\lambda_i \\rho_i \\right] + \\left[ \\sum_{k=1}^{\\infty} \\delta_k^a \\prod_{i=1}^k \\gamma_i \\lambda_i \\rho_i \\right] \\\\\n",
    "\n",
    "&= \\left[ \\delta_0^a \\right] + \\left[ \\gamma_1 \\lambda_1 \\rho_1 \\sum_{k=1}^{\\infty} \\delta_k^a \\prod_{i=2}^k \\gamma_i \\lambda_i \\rho_i \\right] \\\\\n",
    "\n",
    "&= \\left[ R_1 + \\gamma_1 \\overline{V}_1 - Q_0 \\right] + \\gamma_1 \\lambda_1 \\rho_1 [G_1^{\\lambda a} - Q_1] \\tag{based on the initial step} \\\\\n",
    "\n",
    "&= R_1 + \\gamma_1 \\overline{V}_1 + \\gamma_1 \\lambda_1 \\rho_1 [G_1^{\\lambda a} - Q_1] - Q_0\\\\\n",
    "\n",
    "&= R_1 + \\gamma_1 (\\overline{V}_1 + \\lambda_1 \\rho_1 [G_1^{\\lambda a} - Q_1]) - Q_0 \\\\\n",
    "\\end{align*}\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "G_0^{\\lambda a} = R_1 + \\gamma_1 (\\overline{V}_1 + \\lambda_1 \\rho_1 [G_1^{\\lambda a} - Q_1])\n",
    "$$\n",
    "\n",
    "Generalizing for $t$:\n",
    "\n",
    "$$\n",
    "G_t^{\\lambda a} = R_{t+1} + \\gamma_{t+1} (\\overline{V}_{t+1} + \\lambda_{t+1} \\rho_{t+1} [G_{t+1}^{\\lambda a} - Q_{t+1}])\n",
    "$$\n",
    "\n",
    "which is the exact expression to calculate the value of $G_t^{\\lambda a}$ (12.26)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.11\n",
    "\n",
    "**Q**\n",
    "\n",
    "The truncated version of the general off-policy return is denoted $G_{t:h}^{\\lambda a}$. Guess the correct equation for it, based on (12.27).\n",
    "\n",
    "**A**\n",
    "\n",
    "The value of $G_{h:h}^{\\lambda a} = \\overline{V}_h$, and it should be present only in the highest index of $\\delta^a$, with $\\delta_t^a \\doteq R_{t+1} + \\gamma_{t+1} \\overline{V}_{t+1} - Q_t$ (12.28), which means that the highest $t$ for $\\delta_t$ must be $h - 1$, so, based on 12.27:\n",
    "\n",
    "$$\n",
    "G_{t:h}^{\\lambda a} = Q_t + \\sum_{k=t}^{h-1} \\delta_k^a \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i\n",
    "$$\n",
    "\n",
    "which is expected, considering the similar result demonstrated in the Exercise 12.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.12\n",
    "\n",
    "**Q**\n",
    "\n",
    "Show in detail the steps outlined above for deriving (12.29) from (12.27). Start with the update (12.15), substitute $G_t^{\\lambda a}$ from (12.26) for $G_t^{\\lambda}$, then follow similar steps as led to (12.25).\n",
    "\n",
    "**A**\n",
    "\n",
    "Equation 12.29 is:\n",
    "\n",
    "$$\n",
    "\\textbf{z} \\doteq \\gamma_t \\lambda_t \\rho_t \\textbf{z}_{t-1} + \\nabla \\widehat{q}(S_t, A_t, \\textbf{w}_t) \\tag{12.29}\n",
    "$$\n",
    "\n",
    "Equation 12.27 is:\n",
    "\n",
    "$$\n",
    "G_t^{\\lambda a} \\approx \\widehat{q}(S_t, A_t, \\textbf{w}_t) + \\sum_{k=t}^{\\infty} \\delta_k^a \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\tag{12.27}\n",
    "$$\n",
    "\n",
    "Equation 12.26 is:\n",
    "\n",
    "\\begin{align*}\n",
    "G_t^{\\lambda a} &\\doteq R_{t+1} + \\gamma_{t+1} ((1 - \\lambda_{t+1}) \\overline{V}_t(S_{t+1}) + \\lambda_{t+1} [\\rho_{t+1} G_{t+1}^{\\lambda a} + \\overline{V}_t(S_{t+1}) - \\rho_{t+1} \\widehat{q}(S_{t+1}, A_{t+1}, \\textbf{w}_t)]) \\\\\n",
    "&= R_{t+1} + \\gamma_{t+1} (\\overline{V}_t(S_{t+1}) + \\lambda_{t+1} \\rho_{t+1} [G_{t+1}^{\\lambda a} - \\widehat{q}(S_{t+1}, A_{t+1}, \\textbf{w}_t)]) \\tag{12.26}\n",
    "\\end{align*}\n",
    "\n",
    "The steps shown in 12.25 are:\n",
    "\n",
    "\\begin{align*}\n",
    "\\textbf{z}_k &= \\sum_{t=1}^k \\rho_t \\nabla \\widehat{v}(S_t, \\textbf{w}_t) \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\\\\n",
    "\n",
    "&= \\sum_{t=1}^{k-1} \\rho_t \\nabla \\widehat{v}(S_t, \\textbf{w}_t) \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\quad + \\quad \\rho_k \\nabla \\widehat{v}(S_k, \\textbf{w}_k) \\\\\n",
    "\n",
    "&= \\gamma_k \\lambda_k \\rho_k \\underbrace{ \\sum_{t=1}^{k-1} \\rho_t \\nabla \\widehat{v}(S_t, \\textbf{w}_t) \\prod_{i=t+1}^{k-1} \\gamma_i \\lambda_i \\rho_i }_{\\textbf{z}_{k-1}} \\quad + \\quad \\rho_k \\nabla \\widehat{v}(S_k, \\textbf{w}_k) \\\\\n",
    "\n",
    "&= \\rho_k (\\gamma_k \\lambda_k \\textbf{z}_{k-1} + \\nabla \\widehat{v}(S_k, \\textbf{w}_k))\n",
    "\\end{align*}\n",
    "\n",
    "which, changing the index from $k$ to $t$, gives:\n",
    "\n",
    "$$\n",
    "\\textbf{z}_t = \\rho_t (\\gamma_t \\lambda_t \\textbf{z}_{t-1} + \\nabla \\widehat{v}(S_t, \\textbf{w}_t)) \\tag{12.25}\n",
    "$$\n",
    "\n",
    "Starting with the update (12.15):\n",
    "\n",
    "\\begin{align*}\n",
    "\\textbf{w}_{t+1} &\\doteq \\textbf{w}_t + \\alpha [G_t^{\\lambda} - \\widehat{q}(S_t, A_t, \\textbf{w}_t)] \\nabla \\widehat{q}(S_t, A_t, \\textbf{w}_t) \\tag{12.15} \\\\\n",
    "\n",
    "&\\approx \\textbf{w}_t + \\alpha \\left[ \\left( \\widehat{q}(S_t, A_t, \\textbf{w}_t) + \\sum_{k=t}^{\\infty} \\delta_k^a \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\right) - \\widehat{q}(S_t, A_t, \\textbf{w}_t) \\right] \\nabla \\widehat{q}(S_t, A_t, \\textbf{w}_t) \\\\\n",
    "\n",
    "&= \\textbf{w}_t + \\alpha \\left[ \\sum_{k=t}^{\\infty} \\delta_k^a \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i\\right] \\nabla \\widehat{q}(S_t, A_t, \\textbf{w}_t)\n",
    "\\end{align*}\n",
    "\n",
    "The sum of the forward view update is:\n",
    "\n",
    "\\begin{align*}\n",
    "\\sum_{t=1}^{\\infty} (\\textbf{w}_{t+1} - \\textbf{w}_t) &\\approx \\sum_{t=1}^{\\infty} \\left( \\alpha \\left[ \\sum_{k=t}^{\\infty} \\delta_k^a \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i\\right] \\nabla \\widehat{q}(S_t, A_t, \\textbf{w}_t) \\right) \\\\\n",
    "\n",
    "&= \\sum_{t=1}^{\\infty} \\sum_{k=t}^{\\infty} \\left[ \\alpha \\delta_k^a \\nabla \\widehat{q}(S_t, A_t, \\textbf{w}_t) \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\right] \\\\\n",
    "\n",
    "&= \\sum_{k=1}^{\\infty} \\sum_{t=1}^k \\left[ \\alpha \\nabla \\widehat{q}(S_t, A_t, \\textbf{w}_t) \\delta_k^a \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\right] \\tag{using the summation rule: $\\sum_{t=x}^y \\sum_{k=t}^y = \\sum_{k=x}^y \\sum_{t=x}^k$} \\\\\n",
    "\n",
    "&= \\sum_{k=1}^{\\infty} \\alpha \\delta_k^a \\sum_{t=1}^k \\left[ \\nabla \\widehat{q}(S_t, A_t, \\textbf{w}_t) \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\right]\n",
    "\\end{align*}\n",
    "\n",
    "Considering the basic definition of the update:\n",
    "\n",
    "$$\n",
    "\\textbf{w}_{t+1} \\doteq \\textbf{w}_t + \\alpha \\delta_t \\textbf{z}_t \\tag{12.7}\n",
    "$$\n",
    "\n",
    "we have:\n",
    "\n",
    "$$\n",
    "\\textbf{w}_{t+1} - \\textbf{w}_t = \\alpha \\delta_t \\textbf{z}_t\n",
    "$$\n",
    "\n",
    "and consequently:\n",
    "\n",
    "$$\n",
    "\\sum_{t=1}^{\\infty} (\\textbf{w}_{t+1} - \\textbf{w}_t) = \\sum_{t=1}^{\\infty} \\alpha \\delta_t \\textbf{z}_t = \\sum_{k=1}^{\\infty} \\alpha \\delta_k \\textbf{z}_k \\approx \\sum_{k=1}^{\\infty} \\alpha \\delta_k^a \\sum_{t=1}^k \\nabla \\widehat{q}(S_t, A_t, \\textbf{w}_t) \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i\n",
    "$$\n",
    "\n",
    "If the expression of the second sum is the trace at time $k$, then we could update it from its value at time $k - 1$ by:\n",
    "\n",
    "\\begin{align*}\n",
    "\\textbf{z}_k &= \\sum_{t=1}^k \\nabla \\widehat{q}(S_t, A_t, \\textbf{w}_t) \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\\\\n",
    "\n",
    "&= \\sum_{t=1}^{k-1} \\nabla \\widehat{q}(S_t, A_t, \\textbf{w}_t) \\prod_{i=t+1}^k \\gamma_i \\lambda_i \\rho_i \\quad + \\quad \\nabla \\widehat{q}(S_k, A_k, \\textbf{w}_k) \\\\\n",
    "\n",
    "&= \\gamma_k \\lambda_k \\rho_k \\underbrace{ \\sum_{t=1}^{k-1} \\nabla \\widehat{q}(S_t, A_t, \\textbf{w}_t) \\prod_{i=t+1}^{k-1} \\gamma_i \\lambda_i \\rho_i }_{\\textbf{z}_{k-1}} \\quad + \\quad \\nabla \\widehat{q}(S_k, A_k, \\textbf{w}_k) \\\\\n",
    "\n",
    "&= \\gamma_k \\lambda_k \\rho_k \\textbf{z}_{k-1} + \\nabla \\widehat{q}(S_k, A_k, \\textbf{w}_k)\n",
    "\\end{align*}\n",
    "\n",
    "which is the same as equation 12.29 (renaming the index $k$ to $t$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.13\n",
    "\n",
    "**Q**\n",
    "\n",
    "What are the dutch-trace and replacing-trace versions of off-policy eligibility traces for state-value and action-value methods?\n",
    "\n",
    "**A**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
