{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 07 - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.1\n",
    "\n",
    "**Q**\n",
    "\n",
    "In Chapter 6 we noted that the Monte Carlo error can be written as the sum of TD errors (6.6) if the value estimates don’t change from step to step. Show that the n-step error used in (7.2) can also be written as a sum TD errors (again if the value estimates don’t change) generalizing the earlier result.\n",
    "\n",
    "**A**\n",
    "\n",
    "The TD error is defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "\\delta_t \\doteq R_{t+1} + \\gamma V(S_{t+1}) - V(S_t)\n",
    "\\end{align*}\n",
    "\n",
    "Equation 6.6 is:\n",
    "\n",
    "\\begin{align*}\n",
    "G_t - V(S_t) &= R_{t+1} + \\gamma G_{t+1} - V(S_t) + \\gamma V(S_{t+1}) - \\gamma V(S_{t+1}) \\\\\n",
    "&= \\delta_t + \\gamma (G_{t+1} - V(S_{t+1})) \\\\\n",
    "&= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2 (G_{t+2} - V(S_{t+2})) \\\\\n",
    "&= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2 \\delta_{t+2} + ... + \\gamma^{T-t-1} \\delta_{T-1} + \\gamma^{T-t} (G_T - V(S_T)) \\\\\n",
    "&= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2 \\delta_{t+2} + ... + \\gamma^{T-t-1} \\delta_{T-1} + \\gamma^{T-t} (0 - 0) \\\\\n",
    "&= \\sum_{k=t}^{T-1} \\gamma^{k-t} \\delta_k\n",
    "\\end{align*}\n",
    "\n",
    "Equation 7.2 is:\n",
    "\n",
    "\\begin{align*}\n",
    "V_{t+n} (S_t) \\doteq V_{t+n-1} (S_t) + \\alpha[G_{t:t+n} - V_{t+n-1} (S_t)], \\quad 0 \\leq t \\lt T\n",
    "\\end{align*}\n",
    "\n",
    "with:\n",
    "\n",
    "\\begin{align*}\n",
    "G_{t:t+n} \\doteq R_{t+1} + \\gamma R_{t+2} + ... + \\gamma^{n-1} R_{t+n} + \\gamma^n V_{t+n-1} (S_{t+n})\n",
    "\\end{align*}\n",
    "\n",
    "The n-step TD error in 7.2 is the expression whose difference is multiplied by $\\alpha$ to be added to the old value and give the new (estimated) state value:\n",
    "\n",
    "\\begin{align*}\n",
    "G_{t:t+n} - V_{t+n-1} (S_t) &= R_{t+1} + \\gamma R_{t+2} + ... + \\gamma^{n-1} R_{t+n} + \\gamma^n V_{t+n-1} (S_{t+n}) - V_{t+n-1} (S_t) \\\\\n",
    "&= R_{t+1} + \\gamma [R_{t+2} + ... + \\gamma^{n-2} R_{t+n} + \\gamma^{n-1} V_{t+n-1} (S_{t+n})] - V_{t+n-1} (S_t) \\\\\n",
    "&= R_{t+1} + \\gamma G_{t+1:t+n} - V_{t+n-1} (S_t) \\\\\n",
    "&= R_{t+1} + \\gamma [G_{t+1:t+n} + V_{t+n-1} (S_{t+1}) - V_{t+n-1} (S_{t+1})] - V_{t+n-1} (S_t) \\\\\n",
    "&= [R_{t+1} + \\gamma V_{t+n-1} (S_{t+1}) - V_{t+n-1} (S_t)] + \\gamma [G_{t+1:t+n} - V_{t+n-1} (S_{t+1})]\n",
    "\\end{align*}\n",
    "\n",
    "Assuming that the value estimates don’t change, we have:\n",
    "\n",
    "\\begin{align*}\n",
    "V_k = V, \\quad \\forall k\n",
    "\\end{align*}\n",
    "\n",
    "and:\n",
    "\n",
    "\\begin{align*}\n",
    "G_{t:t+n} - V_{t+n-1} (S_t) = G_{t:t+n} - V (S_t)\n",
    "\\end{align*}\n",
    "\n",
    "So:\n",
    "\n",
    "\\begin{align*}\n",
    "G_{t:t+n} - V_{t+n-1} (S_t) &= [R_{t+1} + \\gamma V_{t+n-1} (S_{t+1}) - V_{t+n-1} (S_t)] + \\gamma [G_{t+1:t+n} - V_{t+n-1} (S_{t+1})] \\\\\n",
    "G_{t:t+n} - V (S_t) &= [R_{t+1} + \\gamma V (S_{t+1}) - V (S_t)] + \\gamma [G_{t+1:t+n} - V (S_{t+1})] \\\\\n",
    "&= \\delta_t + \\gamma [G_{t+1:t+n} - V (S_{t+1})] \\\\\n",
    "&= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2 [G_{t+2:t+n} - V (S_{t+2})] \\\\\n",
    "&= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2 \\delta_{t+2} + ... + \\gamma^{n-2} \\delta_{t+n-2} + \\gamma^{n-1} [G_{t+n-1:t+n} - V (S_{t+n-1})] \\\\\n",
    "&= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2 \\delta_{t+2} + ... + \\gamma^{n-2} \\delta_{t+n-2} + \\gamma^{n-1} [R_{t+n} + \\gamma V_{t+n-1} (S_{t+n}) - V (S_{t+n-1})] \\\\\n",
    "&= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2 \\delta_{t+2} + ... + \\gamma^{n-2} \\delta_{t+n-2} + \\gamma^{n-1} [R_{t+n} + \\gamma V(S_{t+n}) - V (S_{t+n-1})] \\\\\n",
    "&= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2 \\delta_{t+2} + ... + \\gamma^{n-2} \\delta_{t+n-2} + \\gamma^{n-1} \\delta_{t+n-1} \\\\\n",
    "&= \\sum_{k=t}^{t+n-1} \\gamma^{k-t} \\delta_k\n",
    "\\end{align*}\n",
    "\n",
    "It's good to take into account that for a final time-step T, the equation corresponds to the Monte Carlo error (t + n = T):\n",
    "\n",
    "\\begin{align*}\n",
    "G_{t:t+n} - V (S_t) &= \\sum_{k=t}^{t+n-1} \\gamma^{k-t} \\delta_k \\\\\n",
    "G_{t:T} - V (S_t) &= \\sum_{k=t}^{T-1} \\gamma^{k-t} \\delta_k\n",
    "\\end{align*}\n",
    "\n",
    "It's also importante to note that the value estimates were considered to not change, but in a real scenario it's expected that they change (see exercise 6.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.2 (programming) \n",
    "\n",
    "**Q**\n",
    "\n",
    "With an n-step method, the value estimates do change from step to step, so an algorithm that used the sum of TD errors (see previous exercise) in place of the error in (7.2) would actually be a slightly different algorithm. Would it be a better algorithm or a worse one? Devise and program a small experiment to answer this question empirically.\n",
    "\n",
    "**A**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
